{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d317f1",
   "metadata": {},
   "source": [
    "# Analysis of random error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53baa39-b207-4c53-b084-4a83327eb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './'\n",
    "\n",
    "data_path   = project_path + '../data/random_error/'\n",
    "\n",
    "graphs_path = project_path + '../graphs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a64345",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726bb83-c6ab-48c3-87f0-3784e5ff64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_EP(directory, silent=False):\n",
    "    if (not silent):\n",
    "        print('  - Cospectra files:')\n",
    "        \n",
    "    file_list = sorted(glob.glob(directory + '**/*.csv', recursive=True))\n",
    "    data_list = []\n",
    "    for idx, fn in enumerate(file_list):\n",
    "        print('    -', fn.split('\\\\')[-1])\n",
    "        # Read file\n",
    "        temp = pd.read_csv(fn, skiprows=[0,2], na_values=-9999)\n",
    "        # Append timestamp\n",
    "        timestamp_fn = fn.split('\\\\')[-1].split('_')[0]\n",
    "        temp['DateTime'] = pd.to_datetime(temp['date'] + ' ' + temp['time'], format='%Y-%m-%d %H:%M')\n",
    "        # shift column 'timestamp' to first position\n",
    "        col = temp.pop('DateTime')\n",
    "        temp.insert(0, 'DateTime', col)\n",
    "        # Append to list of dfs\n",
    "        data_list.append(temp)\n",
    "    # Combine all the read data\n",
    "    df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    # Make the timestamp the middle of the halfhour\n",
    "    df['DateTime'] = df['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    # Drop useless columns\n",
    "    df.drop(columns=['filename','date','time'], inplace=True)\n",
    "    return(df)\n",
    "\n",
    "def add_ecosystem(df):\n",
    "    df = df.copy()\n",
    "    # Add ecosystem\n",
    "    df['Ecosystem'] = np.nan\n",
    "    df.loc[df['DateTime'] < '2019-07-16', 'Ecosystem'] = 'PV desert background'\n",
    "    df.loc[df['DateTime'] >= '2019-07-16', 'Ecosystem'] = 'PV field'\n",
    "    # Create half-hour identifier\n",
    "    df['halfhour'] = df['DateTime'].dt.strftime('%H:%M')\n",
    "    # Create day identifier\n",
    "    df['day'] = df['DateTime'].dt.strftime('%Y-%m-%d')\n",
    "    # shift column 'timestamp' to first position\n",
    "    col = df.pop('halfhour')\n",
    "    df.insert(0, 'halfhour', col)\n",
    "    col = df.pop('day')\n",
    "    df.insert(0, 'day', col)\n",
    "    col = df.pop('Ecosystem')\n",
    "    df.insert(0, 'Ecosystem', col)\n",
    "    col = df.pop('DateTime')\n",
    "    df.insert(0, 'DateTime', col)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ea6f9-1880-41b6-8446-e2ae8980e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "df = load_EP(data_path)\n",
    "df = add_ecosystem(df)\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ea6af-a531-4d49-a7d8-72587102b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns with random errors\n",
    "err_cols = [col for col in df.columns if 'rand_err' in col]\n",
    "print(err_cols)\n",
    "#display(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b409cb6-1008-4d48-94cc-9b175d1e2cc7",
   "metadata": {},
   "source": [
    "### Some stats on the errors\n",
    "\n",
    "#### Sensible heat flux ($H$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86eebe-da8d-4c1b-8816-6779ea91d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "\n",
    "# Z-score: Remove anything more than >2 stddevs away\n",
    "z = np.abs((df['rand_err_H'] - df['rand_err_H'].mean()) / df['rand_err_H'].std())\n",
    "threshold = 2.0\n",
    "outliers = df[z > threshold]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_H']])\n",
    "# Corrected df\n",
    "df2 = df.drop(df[z > threshold].index).copy()\n",
    "\n",
    "# Interquartile range (iqr)\n",
    "q1 = df['rand_err_H'].quantile(0.25)\n",
    "q3 = df['rand_err_H'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "threshold = 1.5\n",
    "outliers = df[(df['rand_err_H'] < q1 - threshold*iqr) | (df['rand_err_H'] > q3 + threshold*iqr)]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_H']])\n",
    "# Corrected df\n",
    "df3 = df.drop(df[(df['rand_err_H'] < q1 - threshold*iqr) | (df['rand_err_H'] > q3 + threshold*iqr)].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93538e-c4da-4434-a9e7-90e63a69d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means after z-score filter\n",
    "print('Means after z-score filter:')\n",
    "grouped = df2.groupby('Ecosystem').agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem',\n",
    "                 'rand_err_H_mean','rand_err_H_std','rand_err_H_max','rand_err_H_min']])\n",
    "print('---')\n",
    "print()\n",
    "\n",
    "# Means after iqr filter\n",
    "print('Means after iqr filter:')\n",
    "grouped = df3.groupby('Ecosystem').agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem',\n",
    "                 'rand_err_H_mean','rand_err_H_std','rand_err_H_max','rand_err_H_min']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d0976-1b85-46cb-aeae-33f0d0741eb7",
   "metadata": {},
   "source": [
    "#### Latent heat flux ($LE$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53760d65-3103-488e-95a2-c3d7a0701ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "\n",
    "# Z-score: Remove anything more than >2 stddevs away\n",
    "z = np.abs((df['rand_err_LE'] - df['rand_err_LE'].mean()) / df['rand_err_LE'].std())\n",
    "threshold = 2.0\n",
    "outliers = df[z > threshold]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_LE']])\n",
    "# Corrected df\n",
    "df2 = df.drop(df[z > threshold].index).copy()\n",
    "\n",
    "# Interquartile range (iqr)\n",
    "q1 = df['rand_err_LE'].quantile(0.25)\n",
    "q3 = df['rand_err_LE'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "threshold = 1.5\n",
    "outliers = df[(df['rand_err_LE'] < q1 - threshold*iqr) | (df['rand_err_LE'] > q3 + threshold*iqr)]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_LE']])\n",
    "# Corrected df\n",
    "df3 = df.drop(df[(df['rand_err_LE'] < q1 - threshold*iqr) | (df['rand_err_LE'] > q3 + threshold*iqr)].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7bdcd9-f9cf-4975-b669-da303b18e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means after z-score filter\n",
    "print('Means after z-score filter:')\n",
    "grouped = df2.groupby('Ecosystem').agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem',\n",
    "                 'rand_err_LE_mean','rand_err_LE_std','rand_err_LE_max','rand_err_LE_min']])\n",
    "print('---')\n",
    "print()\n",
    "\n",
    "# Means after iqr filter\n",
    "print('Means after iqr filter:')\n",
    "grouped = df3.groupby('Ecosystem').agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem',\n",
    "                 'rand_err_LE_mean','rand_err_LE_std','rand_err_LE_max','rand_err_LE_min']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c9131-0f7c-4995-90ad-1fad0c420d2f",
   "metadata": {},
   "source": [
    "### Daily\n",
    "\n",
    "#### Sensible heat flux ($H$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ac6ed-15d3-44f4-834b-62b4e3ae0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "\n",
    "# Z-score: Remove anything more than >2 stddevs away\n",
    "z = np.abs((df['rand_err_H'] - df['rand_err_H'].mean()) / df['rand_err_H'].std())\n",
    "threshold = 2.0\n",
    "outliers = df[z > threshold]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_H']])\n",
    "# Corrected df\n",
    "df2 = df.drop(df[z > threshold].index).copy()\n",
    "\n",
    "# Interquartile range (iqr)\n",
    "q1 = df['rand_err_H'].quantile(0.25)\n",
    "q3 = df['rand_err_H'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "threshold = 1.5\n",
    "outliers = df[(df['rand_err_H'] < q1 - threshold*iqr) | (df['rand_err_H'] > q3 + threshold*iqr)]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_H']])\n",
    "# Corrected df\n",
    "df3 = df.drop(df[(df['rand_err_H'] < q1 - threshold*iqr) | (df['rand_err_H'] > q3 + threshold*iqr)].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72094333-2529-457f-afbb-d2486ff97ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means after z-score filter\n",
    "print('Means after z-score filter:')\n",
    "grouped = df2.groupby(['Ecosystem', 'day']).agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem', 'day',\n",
    "                 'rand_err_H_mean','rand_err_H_std','rand_err_H_max','rand_err_H_min']])\n",
    "print('---')\n",
    "print()\n",
    "\n",
    "# Means after iqr filter\n",
    "print('Means after iqr filter:')\n",
    "grouped = df3.groupby(['Ecosystem', 'day']).agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem', 'day',\n",
    "                 'rand_err_H_mean','rand_err_H_std','rand_err_H_max','rand_err_H_min']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23a4fd-a111-4a96-88b7-502909ee365d",
   "metadata": {},
   "source": [
    "#### Latent heat flux ($LE$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff1f0d-f727-43fb-be50-671bd0e349eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "\n",
    "# Z-score: Remove anything more than >2 stddevs away\n",
    "z = np.abs((df['rand_err_LE'] - df['rand_err_LE'].mean()) / df['rand_err_LE'].std())\n",
    "threshold = 2.0\n",
    "outliers = df[z > threshold]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_LE']])\n",
    "# Corrected df\n",
    "df2 = df.drop(df[z > threshold].index).copy()\n",
    "\n",
    "# Interquartile range (iqr)\n",
    "q1 = df['rand_err_LE'].quantile(0.25)\n",
    "q3 = df['rand_err_LE'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "threshold = 1.5\n",
    "outliers = df[(df['rand_err_LE'] < q1 - threshold*iqr) | (df['rand_err_LE'] > q3 + threshold*iqr)]\n",
    "#display(outliers[['DateTime','Ecosystem', 'rand_err_LE']])\n",
    "# Corrected df\n",
    "df3 = df.drop(df[(df['rand_err_LE'] < q1 - threshold*iqr) | (df['rand_err_LE'] > q3 + threshold*iqr)].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c119c0-266b-4fc5-84fa-17c087a48231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means after z-score filter\n",
    "print('Means after z-score filter:')\n",
    "grouped = df2.groupby(['Ecosystem', 'day']).agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem', 'day',\n",
    "                 'rand_err_LE_mean','rand_err_LE_std','rand_err_LE_max','rand_err_LE_min']])\n",
    "print('---')\n",
    "print()\n",
    "\n",
    "# Means after iqr filter\n",
    "print('Means after iqr filter:')\n",
    "grouped = df3.groupby(['Ecosystem', 'day']).agg(['mean','std','max','min'])\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "display(grouped[['Ecosystem', 'day',\n",
    "                 'rand_err_LE_mean','rand_err_LE_std','rand_err_LE_max','rand_err_LE_min']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67fdf1-62d1-4f70-842c-02a5d1a453e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
