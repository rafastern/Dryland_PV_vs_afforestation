{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resistance table Midday Spring\n",
    "\n",
    "The objective of this script is to automatically generate the radiative fluxes table of this paper, and export it to LaTeX, with the proper t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './'\n",
    "data_path   = project_path + '../../data/'\n",
    "\n",
    "dataset_fn = data_path + 'dataset.csv'\n",
    "\n",
    "#output_path  = project_path + 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fn, index_col=False, silent=False):\n",
    "    if (not silent):\n",
    "        print('-', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=index_col)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "    return(temp)\n",
    "\n",
    "def averaging(temp):\n",
    "    \n",
    "    # define mid-day\n",
    "    temp = temp.loc[(temp['DateTime'].dt.hour >= 10) & (temp['DateTime'].dt.hour < 15)].copy()\n",
    "\n",
    "    # Make mean and std dev\n",
    "    df_means = temp.groupby(['Season','Ecosystem']).mean().reset_index()\n",
    "    df_sds   = temp.groupby(['Season','Ecosystem']).std().reset_index()\n",
    "    # rename columns\n",
    "    df_means.rename(columns={'H': 'H_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'LE': 'LE_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Rn': 'Rn_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Ta': 'Ta_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Ts': 'Ts_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'D_T': 'D_T_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Pa': 'Pa_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'H2O': 'H2O_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Lout': 'Lout_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Lin': 'Lin_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'rho': 'rho_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'cp': 'cp_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'rH': 'rH_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'SWin': 'SWin_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'SWout': 'SWout_mean'}, inplace=True)\n",
    "\n",
    "    df_sds.rename(columns={'H': 'H_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'LE': 'LE_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Rn': 'Rn_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Ta': 'Ta_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Ts': 'Ts_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'D_T': 'D_T_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Pa': 'Pa_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'H2O': 'H2O_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Lout': 'Lout_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Lin': 'Lin_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'rho': 'rho_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'cp': 'cp_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'rH': 'rH_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'SWin': 'SWin_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'SWout': 'SWout_sd'}, inplace=True)\n",
    "    \n",
    "    merged = df_means.merge(df_sds, on=['Season','Ecosystem'])\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    merged = merged[['Season','Ecosystem','H_mean','LE_mean','Rn_mean','Ta_mean','Ts_mean','D_T_mean','Pa_mean','H2O_mean','Lout_mean','Lin_mean','rho_mean','cp_mean',\\\n",
    "                     'H_sd','LE_sd','Rn_sd','Ta_sd','Ts_sd','D_T_sd','Pa_sd','H2O_sd','Lout_sd','Lin_sd','rho_sd','cp_sd','rH_mean','rH_sd','SWin_mean','SWin_sd','SWout_mean','SWout_sd']]\n",
    "    \n",
    "    return(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print('Load data:')\n",
    "all_df = load_data(dataset_fn)\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_df.copy()\n",
    "# When both H and D_T are too small, ignore\n",
    "temp.loc[(np.abs(temp['H']) < 5) | (np.abs(temp['D_T']) < 2), 'rH'] = np.nan\n",
    "# When H and D_T are too close to each other as values, ignore\n",
    "temp.loc[(np.abs(temp['H']) <= (np.abs(temp['D_T']) + 2)) &\n",
    "                (np.abs(temp['H']) >= (np.abs(temp['D_T']) - 2)), 'rH'] = np.nan\n",
    "\n",
    "# At night, we sometimes get rH < 0. Remove\n",
    "temp.loc[(temp['rH'] < 0) & (temp['SWin'] < 5), 'rH'] = np.nan\n",
    "# In fact, negative values are not supposed to be valid at all\n",
    "temp.loc[(temp['rH'] < 0), 'rH'] = np.nan\n",
    "\n",
    "mean_df = averaging(temp)\n",
    "\n",
    "# Create a text of summarised values (mean + stddev)\n",
    "mean_df['Rn'] = mean_df['Rn_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['Rn_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['H'] = mean_df['H_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['H_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['LE'] = mean_df['LE_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['LE_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['Ta'] = mean_df['Ta_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['Ta_sd'].round(1).astype(str) + ')'\n",
    "mean_df['Ts'] = mean_df['Ts_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['Ts_sd'].round(1).astype(str) + ')'\n",
    "mean_df['D_T'] = mean_df['D_T_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['D_T_sd'].round(1).astype(str) + ')'\n",
    "mean_df['rH'] = mean_df['rH_mean'].astype(float).round(0).astype(str) + ' (' + mean_df['rH_sd'].astype(float).round(0).astype(str) + ')'\n",
    "mean_df['Lout'] = mean_df['Lout_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['Lout_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['Lin'] = mean_df['Lin_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['Lin_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "#mean_df['SWout'] = mean_df['SWout_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['SWout_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "#mean_df['SWin'] = mean_df['SWin_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['SWin_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "\n",
    "# Remove the original values\n",
    "mean_df.drop(['H_mean','H_sd','LE_mean','LE_sd','Rn_mean','Rn_sd','Ta_mean','Ta_sd','Ts_mean','Ts_sd','D_T_mean','D_T_sd','Pa_mean','rho_mean','cp_mean',\\\n",
    "              'Pa_sd','H2O_mean','H2O_sd','Lout_mean','Lout_sd','Lin_mean','Lin_sd','rho_sd','cp_sd','rH_mean','rH_sd','SWin_mean','SWin_sd','SWout_mean','SWout_sd'], axis=1, inplace=True)\n",
    "mean_df = mean_df.loc[mean_df['Season'] == 'Spring']\n",
    "\n",
    "# Convert to long format\n",
    "out_df = mean_df.pivot(index='Season', columns='Ecosystem').stack(level=[0])\n",
    "out_df.reset_index(inplace=True)\n",
    "out_df.drop(['Season'], axis=1, inplace=True)\n",
    "out_df.rename(columns={'level_1': 'Parameter'}, inplace=True)\n",
    "display(out_df)\n",
    "\n",
    "#out_df.to_latex(output_path + 'Ketura_Science_resistance_spring.tex', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
