{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975b784b-a542-46ff-ac6b-77ceae89eb23",
   "metadata": {},
   "source": [
    "# Calculation of annual PV field albedo\n",
    "\n",
    "Due to height restrictions imposed by the field operator that were sufficient for flux data, PV field albedo was obtained through a combination of albedo data of its components and their fraction, as viewed from nadir. This script has 2 parts:\n",
    "1. Determination of the fractions\n",
    "2. Calculation of albedo\n",
    "\n",
    "## Model of PV field fractions across the year (cosine curves fits)\n",
    "\n",
    "1. Drone imagery taken over the PV field throughout the day during the summer and autumn campaigns were used to measure the fraction of PV panels as well as exposed and shaded soil\n",
    "2. In order to obtain the shaded soil fraction for each half-hour of the year:\n",
    "   1. A cosine curve was fitted to each campaign’s shade fraction as a function of time\n",
    "   2. An additional set of cosine curves were fitted to the yearly course as a function of day-of-year\n",
    "3. The PV panel fraction was a fixed 51%, and the remaining fraction was exposed soil\n",
    "\n",
    "Important information (based on https://www.suncalc.org/#/29.7692,34.9695,8/2023.03.21/12:21/1/3): \n",
    "- Sumer solstice, highest solar elevation: 21 June 12:41 AM (local time = UTC + 3), i.e. 11:41 Israel winter time\n",
    "- Winter solstice, lowest solar elevation: 22 Dec 11:38 AM (local time = UTC + 2), i.e. 11:38 Israel winter time\n",
    "- The 11:30-12:00 measurement period will be used as the maximum solar elevation throughout the year, or more precisely 11:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471b1d4-c424-47d4-98e3-976d54682d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "\n",
    "from plotnine import *\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31507be4-2c7f-4979-9d2a-3eda114002c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "project_path = './'\n",
    "data_path = project_path + '../data/'\n",
    "\n",
    "# Input data\n",
    "data_fn   = data_path + 'dataset.csv'\n",
    "albedo_fn = data_path + 'afforestation_albedo.csv'\n",
    "sw_fn     = data_path + 'met_data_pv.csv'\n",
    "percentage_manual_fn = data_path + 'PV_percentages_manual.csv'\n",
    "\n",
    "# Output path\n",
    "output_path = project_path + '../data/'\n",
    "out_pv_albedo_seasonal_fn = output_path + 'PV_albedo_campaigns_modelled.csv'\n",
    "out_pv_albedo_annual_fn   = output_path + 'PV_albedo_annual_modelled.csv'\n",
    "\n",
    "# Constants\n",
    "albedo_pv   = 0.05\n",
    "panel_angle = 30\n",
    "\n",
    "pv_percent = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b3334-ca55-4789-ac82-9ad97c58d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fn, index_col=False, silent=False):\n",
    "    if (not silent):\n",
    "        print('  - Loading', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=index_col)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "    return(temp)\n",
    "\n",
    "def load_percentage_manual(fn, silent=False):\n",
    "    if (not silent): print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, decimal=',')\n",
    "    # Organise timestamps\n",
    "    temp['DateTime'] = temp['filename'].str.slice(4, 17)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%y%m%d_%H%M%S')\n",
    "    # Adjust to Israel winter time\n",
    "    temp['DateTime'] = temp['DateTime'] + pd.Timedelta(hours=2)\n",
    "    # Round to 15min\n",
    "    temp['DateTime'] = temp['DateTime'].dt.round('15min')\n",
    "    # Exclude bad data\n",
    "    temp = temp.loc[(temp['comments'] != 'full shadow, clouds')].copy()\n",
    "    # Move timestamp to beginning\n",
    "    col = temp.pop('DateTime')\n",
    "    temp.insert(0, col.name, col, allow_duplicates=True)\n",
    "    # Drop timestamp and other unnecessary columns\n",
    "    temp.drop(['filename','orientation','panels_px','shadow_px','soil_px','total_px'], axis=1, inplace=True)\n",
    "    # Average by time\n",
    "    temp = temp.groupby('DateTime').mean()\n",
    "    temp.reset_index(inplace=True)\n",
    "    # Rename column\n",
    "    temp.rename({'panels': 'panel'}, axis=1, inplace=True)\n",
    "    # Normalise % with panels = 51% (fixed)\n",
    "    shadow = temp['shadow']\n",
    "    soil   = temp['soil']\n",
    "    temp['panel'] = pv_percent\n",
    "    temp['shadow'] = shadow*(100-pv_percent)/(shadow + soil)\n",
    "    temp['soil']   = soil*(100-pv_percent)/(shadow + soil)\n",
    "    return(temp)\n",
    "\n",
    "def add_ecosystem(df):\n",
    "    df = df.copy()\n",
    "    # Add ecosystem\n",
    "    df['Ecosystem'] = np.nan\n",
    "    df.loc[(df['DateTime'] > '2018-03-17') & (df['DateTime'] < '2018-03-22'), 'Ecosystem'] = 'Desert background'\n",
    "    df.loc[(df['DateTime'] > '2018-03-21') & (df['DateTime'] < '2018-03-28'), 'Ecosystem'] = 'PV field'\n",
    "    \n",
    "    df.loc[(df['DateTime'] > '2018-10-15') & (df['DateTime'] < '2018-10-25'), 'Ecosystem'] = 'Desert background'\n",
    "    df.loc[(df['DateTime'] > '2018-10-23') & (df['DateTime'] < '2018-11-01'), 'Ecosystem'] = 'PV field'\n",
    "    \n",
    "    df.loc[(df['DateTime'] > '2019-07-08') & (df['DateTime'] < '2019-07-17'), 'Ecosystem'] = 'Desert background'\n",
    "    df.loc[(df['DateTime'] > '2019-07-15') & (df['DateTime'] < '2019-07-25'), 'Ecosystem'] = 'PV field'\n",
    "    # Season\n",
    "    df['Season'] = np.nan\n",
    "    df.loc[(df['DateTime'] > '2018-03-17') & (df['DateTime'] < '2018-03-28'), 'Season'] = 'Spring'\n",
    "    df.loc[(df['DateTime'] > '2018-10-15') & (df['DateTime'] < '2018-11-01'), 'Season'] = 'Autumn'\n",
    "    df.loc[(df['DateTime'] > '2019-07-08') & (df['DateTime'] < '2019-07-25'), 'Season'] = 'Summer'\n",
    "    \n",
    "    # Create day identifier\n",
    "    df['time'] = df['DateTime'].dt.strftime('%H:%M')\n",
    "    # shift column 'timestamp' to first position\n",
    "    col = df.pop('time')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('Ecosystem')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('Season')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('DateTime')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63275f83-35ce-4bfc-adb3-61cd44d5f0a9",
   "metadata": {},
   "source": [
    "def load_tower(fn, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1], '(Note: slow)')\n",
    "    temp = pd.read_csv(fn, index_col=None)\n",
    "    temp.rename({'date_mid_hour': 'DateTime'}, axis=1, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%d%b%y:%H:%M')\n",
    "    # Remove obsolete columns\n",
    "    temp.drop(['year','date','DOY','month','weekNo','mid_hour','mmyy','Bat_V','Hum_AC'], axis=1, inplace=True)\n",
    "    return(temp)\n",
    "\n",
    "def load_truck(fn, index_col=False, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=index_col)\n",
    "    temp.rename(columns={'date_time': 'DateTime'}, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    temp['DateTime'] = temp['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(temp)\n",
    "\n",
    "def load_meteo_stn(directory, silent=False):\n",
    "    if (not silent):\n",
    "        print('  - Meteo station:')\n",
    "        \n",
    "    file_list = sorted(glob.glob(directory + '**/*.csv', recursive=True))\n",
    "    data_list = []\n",
    "    for idx, filename in enumerate(file_list):\n",
    "        print('    -', filename.split('/')[-1])\n",
    "        temp = pd.read_csv(filename)\n",
    "        data_list.append(temp)\n",
    "    # Combine all the read data\n",
    "    df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    # Fix problems\n",
    "    df.columns = ['station','DateTime', 'Eg_Wm2', 'RH_perc', 'Ta_C', 'u_ms']\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "    # Convert to numbers\n",
    "    df['Eg_Wm2'] = pd.to_numeric(df['Eg_Wm2'], errors='coerce')\n",
    "    df['RH_perc'] = pd.to_numeric(df['RH_perc'], errors='coerce')\n",
    "    df['Ta_C'] = pd.to_numeric(df['Ta_C'], errors='coerce')\n",
    "    df['u_ms'] = pd.to_numeric(df['u_ms'], errors='coerce')\n",
    "    # Average 10min Yotvata data to half-hours\n",
    "    df = df.resample('30min', on='DateTime').mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    df['DateTime'] = df['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e27a69-be24-42df-9b67-3da77ade3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "# Manually detected percentages\n",
    "perc_df = load_percentage_manual(percentage_manual_fn)\n",
    "perc_df = add_ecosystem(perc_df)\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6824088d-e4f1-45a0-b3e5-301ce921961e",
   "metadata": {},
   "source": [
    "print('Loading data...')\n",
    "\n",
    "# Mobile Lab (truck) data\n",
    "ketura_df = load_truck(ketura_fn)\n",
    "ketura_df = add_ecosystem(ketura_df)\n",
    "\n",
    "# Yotvata meteo station\n",
    "meteo_stn = load_meteo_stn(yotvata_fn)\n",
    "\n",
    "# Manual detection of percentages\n",
    "perc_df = load_percentage_manual(percentage_manual_fn)\n",
    "perc_df = add_ecosystem(perc_df)\n",
    "\n",
    "# Yatir dataset, used for diffuse fraction\n",
    "#yatir_full_df = load_tower(yatir_fn) # Load 20 years\n",
    "#yatir_df = yatir_full_df.loc[(yatir_full_df['DateTime'].dt.year == 2018) | (yatir_full_df['DateTime'].dt.year == 2019)].copy()\n",
    "#del [yatir_full_df] # Clean up memory\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c3a55-55e5-4e94-aef6-738bb121da5e",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "- Calculate the day-of-year of the middle of the campaign\n",
    "- Create diurnals for each campaign\n",
    "- Fit cosine curve to each campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741772c8-8e0f-46d8-8071-4108f30686ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show raw data for diagnostics\n",
    "\n",
    "graph_df = perc_df.copy()\n",
    "graph_df['time'] = pd.to_datetime(graph_df['time'], format='%H:%M')\n",
    "graph_df['time'] = graph_df['time'].dt.strftime('%H').astype(float) + graph_df['time'].dt.strftime('%M').astype(float)/60\n",
    "\n",
    "\n",
    "plt = ggplot(graph_df)\n",
    "plt = plt + geom_point(aes(x='time', y='shadow', colour='Season'))\n",
    "plt = plt + labs(x='Time', y='% shadow')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258306f4-3f0d-4517-b331-5a4c89224188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle of campaign\n",
    "#--------------------\n",
    "\n",
    "# Create DOY\n",
    "def create_middle_doy(temp, timestamp_col, group_cols):\n",
    "    temp = temp.copy()\n",
    "    temp['doy'] = temp[timestamp_col].dt.strftime('%j').astype(float)\n",
    "    # Calculate middle\n",
    "    out_df = temp[group_cols + ['doy']].groupby(group_cols).agg(['min','max'])\n",
    "    out_df.reset_index(inplace=True)\n",
    "    out_df.columns = ['_'.join(col).strip('_') for col in out_df.columns.values]\n",
    "    out_df['doy'] = np.round((out_df['doy_min'] + out_df['doy_max'])/2, 0)\n",
    "    # Cleanup\n",
    "    out_df.drop(['doy_min', 'doy_max'], axis=1, inplace=True)\n",
    "    return(out_df)\n",
    "\n",
    "def create_15min_diurnal_df(temp, timestamp_col, group_cols):\n",
    "    temp = temp.copy()\n",
    "    # Collapse percentages to diurnals\n",
    "    temp['DateTime2'] = pd.to_datetime(temp['time'], format='%H:%M')\n",
    "\n",
    "    # set the DateTime column as the index\n",
    "    temp.set_index('DateTime2', inplace=True)\n",
    "    # Remove DateTime, otherwise it crashes\n",
    "    temp2 = temp.drop(['DateTime'], axis=1).copy()\n",
    "    # resample the data to 15-minute intervals and apply a smoothing function (e.g., rolling mean)\n",
    "    out_df = temp2.sort_values(by=['time']).groupby(group_cols).rolling(window=6, min_periods=2).mean()\n",
    "    out_df.reset_index(inplace=True)\n",
    "    out_df.rename({'DateTime2': 'DateTime'}, axis=1, inplace=True)\n",
    "    out_df['time'] = out_df['DateTime'].dt.strftime('%H:%M')\n",
    "    col = out_df.pop('time')\n",
    "    out_df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    out_df.drop(['DateTime'], axis=1, inplace=True)\n",
    "    \n",
    "    # Add repr DOY for this\n",
    "    doy_df = create_middle_doy(temp, timestamp_col, group_cols)\n",
    "    out_df = out_df.merge(doy_df, on=group_cols, how='left')\n",
    "    return(out_df)\n",
    "\n",
    "df_resampled = create_15min_diurnal_df(perc_df, 'DateTime', ['Ecosystem', 'Season'])\n",
    "display(df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6e2f6-5633-4c52-b11a-244efa2a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data again for diagnostics\n",
    "\n",
    "graph_df = df_resampled.copy()\n",
    "graph_df['time'] = pd.to_datetime(graph_df['time'], format='%H:%M')\n",
    "graph_df['time'] = graph_df['time'].dt.strftime('%H').astype(float) + graph_df['time'].dt.strftime('%M').astype(float)/60\n",
    "\n",
    "\n",
    "plt = ggplot(graph_df)\n",
    "plt = plt + geom_point(aes(x='time', y='shadow', colour='Season'))\n",
    "plt = plt + labs(x='Time', y='% shadow')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a0490-5d12-4072-8ce0-1f1748a16238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_decimal(time_data):\n",
    "    # Convert time\n",
    "    time_data = pd.to_datetime(time_data, format='%H:%M')\n",
    "    time_decimal = time_data.dt.strftime('%H').astype(float) + time_data.dt.strftime('%M').astype(float)/60\n",
    "    return(time_decimal)\n",
    "\n",
    "# fit cosine curve\n",
    "def fit_daily_cos_curve(temp):\n",
    "    temp = temp.copy()\n",
    "    # Convert time\n",
    "    temp['time'] = convert_time_to_decimal(temp['time'])\n",
    "\n",
    "    # Keep only data without NAs\n",
    "    temp = temp.loc[~temp['shadow'].isna()].copy()\n",
    "\n",
    "    # Define data for curve fitting\n",
    "    x_data = temp['time']\n",
    "    y_data = temp['shadow']\n",
    "\n",
    "    def shadow_cosine(hour, a, b, c, d):\n",
    "        return a * np.cos(np.radians(hour+b)) + d\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        param, _ = curve_fit(shadow_cosine, x_data, y_data)\n",
    "    \n",
    "    return(param)\n",
    "\n",
    "def shadow_daily(hour, a, b, c, d):\n",
    "    return a * np.cos(np.radians(hour+b)) + d\n",
    "\n",
    "# Run for the entire dataset\n",
    "#---------------------------\n",
    "parameters = []\n",
    "# Iterate over the seasons to fit curves\n",
    "for current_season in df_resampled['Season'].unique():\n",
    "    current_doy = df_resampled.loc[df_resampled['Season'] == current_season, 'doy'].unique()[0]\n",
    "    # Fit the curve\n",
    "    param = fit_daily_cos_curve(df_resampled.loc[df_resampled['Season'] == current_season])\n",
    "    param = [current_season, current_doy] + list(param)\n",
    "    parameters.append(param)\n",
    "    pass\n",
    "param_df = pd.DataFrame(parameters, columns = ['Season', 'doy', 'a', 'b', 'c', 'd'])\n",
    "display(param_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222ab3c-d552-4531-ae55-9c976f854e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for diagnostics: Summer\n",
    "#-----------------------------\n",
    "\n",
    "params = param_df.loc[param_df['Season'] == 'Summer']\n",
    "\n",
    "# Raw data to be shown in the plot\n",
    "x_data = convert_time_to_decimal(df_resampled.loc[df_resampled['Season'] == 'Summer', 'time'])\n",
    "y_data = df_resampled.loc[df_resampled['Season'] == 'Summer', 'shadow']\n",
    "\n",
    "# Model data\n",
    "x_data_model = np.arange(0,24, 0.5)\n",
    "y_data_model = shadow_daily(x_data_model, params['a'].values[0], params['b'].values[0], params['c'].values[0], params['d'].values[0])\n",
    "y_data_model = np.where(y_data_model > 0, y_data_model, np.nan)\n",
    "\n",
    "# Plot\n",
    "plt = ggplot()\n",
    "plt = plt + geom_line(aes(x=x_data_model, y=y_data_model))\n",
    "plt = plt + geom_point(aes(x=x_data, y=y_data), colour='blue')\n",
    "plt = plt + labs(x='Time', y='% shadow')\n",
    "plt = plt + ggtitle('Summer')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)\n",
    "\n",
    "# Plot for diagnostics: Autumn\n",
    "#-----------------------------\n",
    "\n",
    "params = param_df.loc[param_df['Season'] == 'Autumn']\n",
    "\n",
    "# Raw data to be shown in the plot\n",
    "x_data = convert_time_to_decimal(df_resampled.loc[df_resampled['Season'] == 'Autumn', 'time'])\n",
    "y_data = df_resampled.loc[df_resampled['Season'] == 'Autumn', 'shadow']\n",
    "\n",
    "# Model data\n",
    "x_data_model = np.arange(0,24, 0.5)\n",
    "y_data_model = shadow_daily(x_data_model, params['a'].values[0], params['b'].values[0], params['c'].values[0], params['d'].values[0])\n",
    "y_data_model = np.where(y_data_model > 0, y_data_model, np.nan)\n",
    "\n",
    "# Plot\n",
    "plt = ggplot()\n",
    "plt = plt + geom_line(aes(x=x_data_model, y=y_data_model))\n",
    "plt = plt + geom_point(aes(x=x_data, y=y_data), colour='blue')\n",
    "plt = plt + labs(x='Time', y='% shadow')\n",
    "plt = plt + ggtitle('Autumn')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed6dae4-95a8-4b91-bb2c-102207b292de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df with some times of day for seasonal fitting\n",
    "#----------------------------------------------------------\n",
    "from itertools import product\n",
    "\n",
    "# Prepare dataframe\n",
    "seasons = ['Summer', 'Autumn']\n",
    "times = np.arange(0, 24, 0.25)\n",
    "cols = list(product(seasons, times))\n",
    "t_df = pd.DataFrame(cols, columns=['Season','time'])\n",
    "\n",
    "# Fill with necessary information\n",
    "t_df['doy'] = np.nan\n",
    "t_df['shadow'] = np.nan\n",
    "shadow_perc = []\n",
    "for current_season in t_df['Season'].unique():\n",
    "    current_doy = df_resampled.loc[df_resampled['Season'] == current_season, 'doy'].unique()[0]\n",
    "    params = param_df.loc[param_df['Season'] == current_season]\n",
    "    # Fit the curve\n",
    "    shadow_perc = list(shadow_daily(t_df.loc[t_df['Season'] == current_season, 'time'],\n",
    "                                              params['a'].values[0], params['b'].values[0], params['c'].values[0], params['d'].values[0]))\n",
    "    t_df.loc[t_df['Season'] == current_season, 'doy'] = current_doy\n",
    "    t_df.loc[t_df['Season'] == current_season, 'shadow'] = shadow_perc\n",
    "    pass\n",
    "\n",
    "display(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39bbc5-3264-498b-8e1e-eb31052f2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit annual cosine curve\n",
    "#-------------------------\n",
    "def fit_annual_cos_curve(temp):\n",
    "    temp = temp.copy()\n",
    "    \n",
    "    # The highest sun elevation (smallest shadow, summer solstice) is on the 21st of June\n",
    "    # The lowest sun elevation (largest shadow, winter solstice) is on the 22st of December\n",
    "    doy_summer_solstice = pd.Series(pd.to_datetime('2019-06-21', format='%Y-%m-%d')).dt.strftime('%j').astype(float).values[0]\n",
    "    doy_winter_solstice = pd.Series(pd.to_datetime('2019-12-22', format='%Y-%m-%d')).dt.strftime('%j').astype(float).values[0]\n",
    "\n",
    "    # Fit a cosine curve. The offset of the highest and lowest point of the sun from the end and middle of the year is:\n",
    "    offset = np.mean([365/2-doy_summer_solstice, 365-doy_winter_solstice])\n",
    "\n",
    "    # Define x and y data for curve fitting\n",
    "    x_data = list(temp['doy'])\n",
    "    y_data = list(temp['shadow'])\n",
    "\n",
    "    # Define a cosine-based function with two parameters\n",
    "    # a and b represent the amplitude, and phase shift, respectively.\n",
    "    def shadow_perc_from_doy(doy, a, c):\n",
    "        return a * np.cos(np.radians((doy-365/2+offset)*360/364)) + c\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        param, _ = curve_fit(shadow_perc_from_doy, x_data, y_data)\n",
    "    \n",
    "    return(list(param) + [offset])\n",
    "\n",
    "\n",
    "# Prepare a df to fill for each 15min period, with the fit parameters for the shade percentage as a function of doy\n",
    "doy_list = []\n",
    "for current_time in t_df['time'].unique():\n",
    "    # Fit the curve\n",
    "    params = fit_annual_cos_curve(t_df.loc[t_df['time'] == current_time])\n",
    "    doy_list.append([current_time] + list(params))\n",
    "    pass\n",
    "doy_df = pd.DataFrame(doy_list, columns = ['time', 'a', 'c', 'offset'])\n",
    "#display(doy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d8d21-1ff9-4315-9b89-6c50e16c621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-define shade function, to apply\n",
    "def shadow_perc_from_doy(doy, a, c, pv_percent, offset=9.75):\n",
    "    shadow_perc = a * np.cos(np.radians((doy-365/2+offset)*360/364)) + c\n",
    "    # Correction for 0% shade, or complete shade\n",
    "    shadow_perc = np.where(shadow_perc < 0, 0, shadow_perc)\n",
    "    shadow_perc = np.where(shadow_perc > (100-pv_percent), (100-pv_percent), shadow_perc)\n",
    "    return shadow_perc\n",
    "\n",
    "# Fill the entire year's worth of shadow %\n",
    "#-----------------------------------------\n",
    "from itertools import product\n",
    "\n",
    "# Prepare dataframe\n",
    "doy  = np.arange(1,366)\n",
    "time = t_df['time'].unique()\n",
    "cols = list(product(doy, time))\n",
    "percentage_df = pd.DataFrame(cols, columns=['doy','time'])\n",
    "\n",
    "# Fill with necessary information\n",
    "percentage_df = percentage_df.merge(doy_df, on='time', how='left')\n",
    "percentage_df['shadow'] = shadow_perc_from_doy(percentage_df['doy'], percentage_df['a'], percentage_df['c'], pv_percent)\n",
    "# Cleanup\n",
    "percentage_df.drop(['a', 'c', 'offset'], axis=1, inplace=True)\n",
    "\n",
    "# Fill in panel and soil\n",
    "#-----------------------\n",
    "percentage_df['panel'] = pv_percent\n",
    "percentage_df['soil'] = 100 - percentage_df['panel'] - percentage_df['shadow']\n",
    "\n",
    "# Check\n",
    "#display(percentage_df)\n",
    "\n",
    "plt = ggplot(percentage_df.loc[percentage_df['time'] == 9.00])\n",
    "plt = plt + geom_line(aes(x='doy', y='shadow'))\n",
    "plt = plt + labs(x='Day of year', y='% shadow')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c1e6a-fb0f-4b86-8750-fa2d4996c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "def save_percentage_data(fn, temp):\n",
    "    temp = temp.copy()\n",
    "    # Convert times back to normal format\n",
    "    temp['time'] = temp['time'].apply(lambda x: '{:02.0f}:{:02.0f}'.format(*divmod(x * 60, 60)))\n",
    "    temp.to_csv(output_path + 'PV_percentages_modelled.csv', index=False)\n",
    "    pass\n",
    "\n",
    "save_percentage_data(output_path + 'PV_percentages_modelled.csv', percentage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe5d064-9244-40a4-b4fc-69c3ba264f36",
   "metadata": {},
   "source": [
    "## Annual albedo calculation\n",
    "\n",
    "Base albedo ($\\alpha$) values:\n",
    "- PV panels: 0.05 (fixed)\n",
    "- Exposed soil: Extracted as the equivalent of PV desert background albedo\n",
    "- Shaded soil: Exposed soil $\\alpha$, multiplied by diffuse radiation fraction (Methods S5), obtained from above-canopy measurements at the nearby afforestation research station\n",
    "\n",
    "Calculation method:\n",
    "1. Extract the soil albedo from the desert, as diurnals\n",
    "2. Obtain the diffuse fraction from the nearby afforestation research site data\n",
    "3. Seasonal and annual $\\alpha$: Weighted means by $S_{in}$ across the seasonal campaigns or the entire year, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f74a24-4e18-4d61-9648-d2fd464f5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_SWR(temp):\n",
    "    temp = temp.copy()\n",
    "    # Fix bad SW values\n",
    "    temp.loc[temp['SWin'] < 1, 'SWin'] = 0\n",
    "    temp.loc[temp['SWout'] < 1, 'SWout'] = 0\n",
    "    temp.loc[temp['SWin'] < 1, 'SWout'] = 0\n",
    "    temp.loc[temp['PARin'] <= 0, 'SWin'] = 0\n",
    "    temp.loc[temp['PARin'] <= 0, 'SWout'] = 0\n",
    "    temp.loc[temp['PARout'] <= 0, 'SWin'] = 0\n",
    "    temp.loc[temp['PARout'] <= 0, 'SWout'] = 0\n",
    "    return(temp)\n",
    "\n",
    "def get_diurnal_soil_albedo(temp):\n",
    "    temp = fix_SWR(temp)\n",
    "    \n",
    "    temp['time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "    \n",
    "    # Re-calculate albedo from SW measurements (relevant for the desert)\n",
    "    temp['albedo'] = np.nan\n",
    "    temp['albedo'] = temp['SWout'] / temp['SWin']\n",
    "\n",
    "    # Extract desert albedo & rename. This will be used for the soil & shade fractions of the PV field\n",
    "    desert_albedo = temp.loc[(temp['Ecosystem'] == 'PV desert background'),['time','Season','albedo']].copy()\n",
    "    desert_albedo.rename({'albedo': 'albedo_soil'}, axis=1, inplace=True)\n",
    "\n",
    "    # Collapse to diurnals\n",
    "    desert_albedo = desert_albedo.groupby(['time', 'Season']).mean()\n",
    "    desert_albedo.reset_index(inplace = True)\n",
    "    \n",
    "    return(desert_albedo)\n",
    "\n",
    "def get_diffuse_data(temp):\n",
    "    # Afforestation dataset, used for diffuse fraction\n",
    "    temp = temp.loc[(temp['DateTime'].dt.year == 2018) | (temp['DateTime'].dt.year == 2019)].copy()\n",
    "    \n",
    "    # Calculate diffuse fraction in Yatir (Assuming it's the same in Ketura)\n",
    "    temp['f_dif'] = temp['SWdif'] / temp['SWin']\n",
    "    \n",
    "    return(temp[['DateTime','f_dif']])\n",
    "\n",
    "def interpolate_val(temp):\n",
    "    temp = temp.copy()\n",
    "    \n",
    "    temp['time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "    \n",
    "    for t in temp['time'].unique():\n",
    "        temp.loc[temp['time'] == t, 'f_dif'] = temp.loc[temp['time'] == t, 'f_dif'].rolling(window=14, min_periods=1).mean() #interpolate(limit = 5)\n",
    "        \n",
    "    temp.drop(['time'], axis=1, inplace=True)\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ec149-e833-4e4f-a4cc-5728a68051cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Seasonal albedo calculation:')\n",
    "\n",
    "# All data\n",
    "df = load_data(data_fn)\n",
    "df['DateTime'] = df['DateTime'] + pd.Timedelta('15min')\n",
    "albedo_df = load_data(albedo_fn) # Dataset also contains shortwave & diffuse radiation\n",
    "\n",
    "print('  - Extracting PV desert background albedo')\n",
    "# Obtain desert soil albedo\n",
    "pv_desert_albedo = get_diurnal_soil_albedo(df)\n",
    "\n",
    "print('  - Extracting diffuse fraction from nearby afforestation site')\n",
    "# Get diffuse radiation from afforestation site\n",
    "dif_df = get_diffuse_data(albedo_df)\n",
    "# Make rolling means interpolating the diffuse radiation\n",
    "dif_df = interpolate_val(dif_df)\n",
    "\n",
    "print('  - Adding time & DOY variables')\n",
    "# Add day-of-year\n",
    "df['doy']  = df['DateTime'].dt.strftime('%j').astype(int)\n",
    "df['time'] = df['DateTime'].dt.strftime('%H:%M')\n",
    "\n",
    "print('  - Extracting relevant data')\n",
    "# Extract measurement times in the PV field\n",
    "pv_albedo = df.loc[df['Ecosystem'] == 'PV field', ['DateTime','doy','time','Season','SWin']].copy()\n",
    "pv_albedo.loc[pv_albedo['SWin'] < 0, 'SWin'] = 0\n",
    "\n",
    "print('  - Merging with PV field fractions, diffuse fraction & PV desert background albedo')\n",
    "# Add PV field fractions\n",
    "percentages = percentage_df.copy()\n",
    "percentages['time'] = percentages['time'].apply(lambda x: '{:02.0f}:{:02.0f}'.format(*divmod(x * 60, 60)))\n",
    "percentages['shadow'] = percentages['shadow']*0.01\n",
    "percentages['panel']  = percentages['panel']*0.01\n",
    "percentages['soil']   = percentages['soil']*0.01\n",
    "pv_albedo = pv_albedo.merge(percentages, on=['doy','time'], how='left')\n",
    "\n",
    "# Add diffuse fraction\n",
    "pv_albedo = pv_albedo.merge(dif_df, on=['DateTime'], how='left')\n",
    "\n",
    "# Add soil albedo\n",
    "pv_albedo = pv_albedo.merge(pv_desert_albedo, on=['Season','time'], how='left')\n",
    "\n",
    "print('  - Calculating shade albedo (according to Methods S5)')\n",
    "# Calculate shade albedo\n",
    "pv_albedo['albedo_shade'] = pv_albedo['albedo_soil'] * pv_albedo['f_dif']\n",
    "\n",
    "print('  - Calculating PV field albedo based on fractions')\n",
    "# Calculate PV field albedo based on percentages\n",
    "pv_albedo['albedo'] = pv_albedo['albedo_soil'] * pv_albedo['soil'] \\\n",
    "                    + pv_albedo['albedo_shade'] * pv_albedo['shadow'] \\\n",
    "                    + albedo_pv * pv_albedo['panel']\n",
    "\n",
    "print('  - Saving data to', out_pv_albedo_seasonal_fn)\n",
    "# Save data\n",
    "pv_albedo.to_csv(out_pv_albedo_seasonal_fn, index=False)\n",
    "\n",
    "print('Done...')\n",
    "\n",
    "# Show some example data\n",
    "display(pv_albedo.loc[pv_albedo['time'] == '12:15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a070b5-e4db-4e61-8c5b-b58ad0fdd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    values = np.ma.masked_invalid(values)\n",
    "    # Return the weighted average and standard deviation.\n",
    "    average = np.ma.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.ma.average((values-average)**2, weights=weights)\n",
    "    \n",
    "    maximum = np.max(values)\n",
    "    minimum = np.min(values)\n",
    "    return (average, np.sqrt(variance), maximum, minimum)\n",
    "\n",
    "print('Spring:')\n",
    "spring = pv_albedo.loc[pv_albedo['Season'] == 'Spring']\n",
    "print(weighted_avg_and_std(spring['albedo'], spring['SWin']))\n",
    "print()\n",
    "\n",
    "print('Summer:')\n",
    "summer = pv_albedo.loc[pv_albedo['Season'] == 'Summer']\n",
    "print(weighted_avg_and_std(summer['albedo'], summer['SWin']))\n",
    "print()\n",
    "\n",
    "print('Autumn:')\n",
    "autumn = pv_albedo.loc[pv_albedo['Season'] == 'Autumn']\n",
    "print(weighted_avg_and_std(autumn['albedo'], autumn['SWin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706049a-aeb5-481c-9784-cbf5036979a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pv_albedo.copy()\n",
    "graph_df['time'] = graph_df['DateTime'].dt.strftime('%H%M').astype(int)\n",
    "\n",
    "plt = ggplot(graph_df)\n",
    "plt = plt + geom_point(aes(x='time', y='shadow', colour = 'Season'))\n",
    "plt = plt + labs(x='Time', y='% shadow')\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16609e-d22a-4c9e-b730-3fba7c3f7ac6",
   "metadata": {},
   "source": [
    "## Annual Albedo\n",
    "\n",
    "We assume that the desert soil albedo is constant across the year, using data of all the campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b90d18-36f0-41fd-a3d9-f9228232d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diurnal_soil_albedo_annual(temp):\n",
    "    temp = fix_SWR(temp)\n",
    "    \n",
    "    temp['time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "\n",
    "    # Re-calculate albedo from SW measurements (relevant for the desert)\n",
    "    temp['albedo'] = np.nan\n",
    "    temp['albedo'] = temp['SWout'] / temp['SWin']\n",
    "\n",
    "    # Extract desert albedo & rename. This will be used for the soil & shade fractions of the PV field\n",
    "    desert_albedo = temp.loc[temp['Ecosystem'] == 'PV desert background',['time','albedo','SWin']].copy()\n",
    "    desert_albedo.rename({'albedo': 'albedo_soil'}, axis=1, inplace=True)\n",
    "\n",
    "    # Collapse to diurnals\n",
    "    desert_albedo = desert_albedo.groupby(['time']).mean()\n",
    "    desert_albedo.reset_index(inplace = True)\n",
    "    \n",
    "    return(desert_albedo)\n",
    "\n",
    "def get_diffuse_data_annual(temp):\n",
    "    # Afforestation dataset, used for diffuse fraction\n",
    "    temp = temp.loc[(temp['DateTime'].dt.year == 2018) | (temp['DateTime'].dt.year == 2019)].copy()\n",
    "    \n",
    "    # Calculate diffuse fraction in Yatir (Assuming it's the same in Ketura)\n",
    "    temp['f_dif'] = temp['SWdif'] / temp['SWin']\n",
    "    \n",
    "    # Create columns\n",
    "    temp['doy'] = temp['DateTime'].dt.strftime('%j').astype(int)\n",
    "    temp['time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "    \n",
    "    # Summarise\n",
    "    summarised = temp[['doy', 'time', 'f_dif']].groupby(['doy', 'time']).mean()\n",
    "    summarised.reset_index(inplace=True)\n",
    "    return(summarised)\n",
    "\n",
    "def annual_SWin(temp, SWin_col):\n",
    "    temp = temp.copy()\n",
    "    \n",
    "    # Rename column\n",
    "    temp.rename({SWin_col: 'SWin'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Replace NAs at night\n",
    "    temp.loc[temp['SWin'].isna(), 'SWin'] = 0\n",
    "    \n",
    "    # Create columns\n",
    "    temp['doy'] = temp['DateTime'].dt.strftime('%j').astype(int)\n",
    "    temp['time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "    \n",
    "    # Summarise\n",
    "    summarised = temp[['doy', 'time', 'SWin']].groupby(['doy', 'time']).mean()\n",
    "    summarised.reset_index(inplace=True)\n",
    "    return(summarised)\n",
    "\n",
    "def weighted_avg_and_std(values, weights):\n",
    "    values = np.ma.masked_invalid(values)\n",
    "    # masked_arr = np.ma.masked_array(arr, np.isnan(arr))\n",
    "    \n",
    "    # Return the weighted average and standard deviation.\n",
    "    average = np.ma.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.ma.average((values-average)**2, weights=weights)\n",
    "    \n",
    "    maximum = np.max(values)\n",
    "    minimum = np.min(values)\n",
    "    return (average, np.sqrt(variance), maximum, minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c47b0-60a1-4a19-bc8b-2b72a4d46227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Annual albedo calculation:')\n",
    "\n",
    "# All data\n",
    "df = load_data(data_fn)\n",
    "df['DateTime'] = df['DateTime'] + pd.Timedelta('15min')\n",
    "albedo_df = load_data(albedo_fn) # Dataset also contains shortwave & diffuse radiation\n",
    "# Meteo station SWin\n",
    "sw_df = load_data(sw_fn)\n",
    "\n",
    "print('  - Extracting PV desert background albedo')\n",
    "# Obtain desert soil albedo\n",
    "pv_desert_albedo = get_diurnal_soil_albedo_annual(df)\n",
    "\n",
    "mean, std, maximum, minimum = weighted_avg_and_std(pv_desert_albedo['albedo_soil'], pv_desert_albedo['SWin'])\n",
    "print('    - Mean: ', str(np.round(mean, 2)) + '±' + str(np.round(std, 3)))\n",
    "print('    - Max.: ', str(np.round(maximum, 2)))\n",
    "print('    - Min.: ', str(np.round(minimum, 2)))\n",
    "mean_desert = mean\n",
    "std_desert  = std\n",
    "\n",
    "# Get shortwave radiation from meteo station, as DOY and time (required for weighted average)\n",
    "print('  - Obtaining SWR from nearby meteo station (annual diurnal, based on 2018-2019)')\n",
    "sw_df = annual_SWin(sw_df, 'SWin')\n",
    "pv_desert_albedo.rename({'SWin':'SWin_desert'}, axis=1, inplace=True)\n",
    "pv_albedo = sw_df.merge(pv_desert_albedo, on=['time'], how='left')\n",
    "\n",
    "print('  - Merging with PV field fractions, diffuse fraction & PV desert background albedo')\n",
    "# Add PV field fractions\n",
    "percentages = percentage_df.copy()\n",
    "percentages['time'] = percentages['time'].apply(lambda x: '{:02.0f}:{:02.0f}'.format(*divmod(x * 60, 60)))\n",
    "percentages['shadow'] = percentages['shadow']*0.01\n",
    "percentages['panel']  = percentages['panel']*0.01\n",
    "percentages['soil']   = percentages['soil']*0.01\n",
    "pv_albedo = pv_albedo.merge(percentages, on=['doy','time'], how='left')\n",
    "\n",
    "print('  - Extracting diffuse fraction from nearby afforestation site')\n",
    "# Get diffuse radiation from afforestation site\n",
    "dif_df = get_diffuse_data_annual(albedo_df)\n",
    "\n",
    "# Add diffuse fraction\n",
    "pv_albedo = pv_albedo.merge(dif_df, on=['doy','time'], how='left')\n",
    "\n",
    "# Calculate shade albedo\n",
    "print('  - Calculate shade albedo')\n",
    "pv_albedo['albedo_shade'] = pv_albedo['albedo_soil'] * pv_albedo['f_dif']\n",
    "\n",
    "# Calculate PV field albedo based on percentages\n",
    "print('  - Calculate PV field albedo')\n",
    "pv_albedo['albedo'] = pv_albedo['albedo_soil'] * pv_albedo['soil'] \\\n",
    "                    + pv_albedo['albedo_shade'] * pv_albedo['shadow'] \\\n",
    "                    + albedo_pv * pv_albedo['panel']\n",
    "\n",
    "# Save data\n",
    "print('  - Save data to ' + out_pv_albedo_annual_fn)\n",
    "pv_albedo.to_csv(out_pv_albedo_annual_fn, index=False)\n",
    "\n",
    "# Calculate weighted mean\n",
    "print('  - Calculate weighted mean')\n",
    "mean, std, maximum, minimum = weighted_avg_and_std(pv_albedo['albedo'], pv_albedo['SWin'])\n",
    "print('    - Mean: ', str(np.round(mean, 2)) + '±' + str(np.round(std, 3)))\n",
    "print('    - Max.: ', str(np.round(maximum, 2)))\n",
    "print('    - Min.: ', str(np.round(minimum, 2)))\n",
    "mean_pv = mean\n",
    "std_pv  = std\n",
    "\n",
    "print('  - Change in albedo from installing PV')\n",
    "delta_albedo = mean_desert - mean_pv\n",
    "std_delta_albedo = np.sqrt(std_desert**2 + std_pv**2)\n",
    "print('    - Mean: ', str(np.round(delta_albedo, 2)) + '±' + str(np.round(std_delta_albedo, 3)))\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2725e-84a1-43f9-a6c0-9412f6ac1ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b2bb2-87aa-4741-bd08-46f799de61c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
