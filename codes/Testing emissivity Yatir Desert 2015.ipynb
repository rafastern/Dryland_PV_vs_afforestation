{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table with for Ketura Science paper\n",
    "\n",
    "The objective of this script is to automatically generate the radiative fluxes table of this paper, and export it to LaTeX, with the proper t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import glob\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy import signal\n",
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n",
    "from scipy import stats\n",
    "import os\n",
    "from plotnine.data import mtcars\n",
    "from functools import reduce\n",
    "from itertools import product, combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_path = 'D:/Users/Rafaels/Dropbox/Doutorado/Working/Ketura/'   # Weizmann desktop\n",
    "project_path = 'C:/Users/rafas/Dropbox/Doutorado/Working/Ketura/'     # notebook\n",
    "input_path   = project_path + '01_data/'\n",
    "output_path  = project_path + '02_output/'\n",
    "graphs_path  = project_path + '03_graphs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads all data in the folder\n",
    "def load_all_data(path):\n",
    "    file_list = sorted(glob.glob(path + '*corr.csv', recursive=True))\n",
    "\n",
    "    data_list = []\n",
    "    for filename in file_list:\n",
    "        fn_without_path = filename.replace(path[:-1], \"\")[1:]\n",
    "        print(\"Loading\", fn_without_path)\n",
    "        \n",
    "        temp = pd.read_csv(filename)\n",
    "        # attribute Season and Ecosystem\n",
    "        temp['Ecosystem'] = fn_without_path.split(' ')[2]\n",
    "        temp['Year'] = fn_without_path.split(' ')[5]\n",
    "        temp['Month'] = fn_without_path.split(' ')[4]\n",
    "        temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "        \n",
    "        temp.loc[temp['Month'] == 'July', 'Season'] = 'Summer'\n",
    "        temp.loc[temp['Month'] == 'October', 'Season'] = 'Autumn'\n",
    "        temp.loc[temp['Month'] == 'March', 'Season'] = 'Spring'\n",
    "        temp.loc[temp['Ecosystem'] == 'Solar', 'Ecosystem'] = 'PV field'\n",
    "        temp.loc[temp['Ecosystem'] == 'Desert', 'Ecosystem'] = 'Desert background'\n",
    "        temp.loc[temp['Ecosystem'] == 'Yatir', 'Ecosystem'] = 'Yatir desert'\n",
    "        \n",
    "        data_list.append(temp)\n",
    "        \n",
    "    # Combine all the read data\n",
    "    df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Rename\n",
    "    df.rename(columns={'H_mdsgf_SH': 'H'}, inplace=True)\n",
    "    df.rename(columns={'LE_mdsgf_SLE': 'LE'}, inplace=True)\n",
    "    df.rename(columns={'LW_IN_average_corr': 'Lin'}, inplace=True)\n",
    "    df.rename(columns={'LW_OUT_average_corr': 'Lout'}, inplace=True)\n",
    "    df.rename(columns={'SW_IN_average': 'SWin'}, inplace=True)\n",
    "    df.rename(columns={'SW_OUT_average': 'SWout'}, inplace=True)\n",
    "    df.rename(columns={'PA_average': 'Pa'}, inplace=True)\n",
    "\n",
    "    \n",
    "    # Convert columns to float\n",
    "    df['H']  = pd.to_numeric(df['H'], downcast=\"float\")\n",
    "    df['LE'] = pd.to_numeric(df['LE'], downcast=\"float\")\n",
    "    df['Lin']  = pd.to_numeric(df['Lin'], downcast=\"float\")\n",
    "    df['Lout'] = pd.to_numeric(df['Lout'], downcast=\"float\")\n",
    "    df['SWin']  = pd.to_numeric(df['SWin'], downcast=\"float\")\n",
    "    df['SWout'] = pd.to_numeric(df['SWout'], downcast=\"float\")\n",
    "    df['H2O'] = pd.to_numeric(df['H2O'], downcast=\"float\")\n",
    "    df['Pa'] = pd.to_numeric(df['Pa'], downcast=\"float\")\n",
    "    df['Temperaturek']  = pd.to_numeric(df['TA_average'], downcast=\"float\")\n",
    "    \n",
    "    df['Ta']  = df['Temperaturek'] - 273.15\n",
    "\n",
    "    # Calculating Rn\n",
    "    df['Rn'] = df['SWin'] - df['SWout'] + df['Lin'] - df['Lout']\n",
    "    df['Rn_from_drone'] = df['SWin'] - df['SWout'] + df['Lin'] - df['Lout']\n",
    "    \n",
    "    # Calculating temperature from lout\n",
    "    # Constants\n",
    "    sigma = 5.670374419*10**(-8) # Stefan-Boltzmann constant\n",
    "    \n",
    "    df['Ts'] = ((df['Lout']/(0.89*sigma))**0.25) - 273.15\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    df = df[['DateTime','Season','Ecosystem','Lin','Lout']]\n",
    "    \n",
    "    display (df)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def rename_and_convert_drone(df):\n",
    "    \n",
    "    # Rename\n",
    "    df.rename(columns={'H_mdsgf_SH': 'H'}, inplace=True)\n",
    "    df.rename(columns={'LE_mdsgf_SLE': 'LE'}, inplace=True)\n",
    "    df.rename(columns={'LW_IN_average_corr': 'Lin_from_drone'}, inplace=True)\n",
    "    df.rename(columns={'LWout_corr': 'Lout_from_drone'}, inplace=True)\n",
    "    df.rename(columns={'SW_IN_average': 'SWin'}, inplace=True)\n",
    "\n",
    "       \n",
    "    # Convert columns to float\n",
    "    df['H']  = pd.to_numeric(df['H'], downcast=\"float\")\n",
    "    df['LE'] = pd.to_numeric(df['LE'], downcast=\"float\")\n",
    "    df['Lin']  = pd.to_numeric(df['Lin_from_drone'], downcast=\"float\")\n",
    "    df['Lout'] = pd.to_numeric(df['Lout_from_drone'], downcast=\"float\")\n",
    "    df['SWin']  = pd.to_numeric(df['SWin'], downcast=\"float\")\n",
    "\n",
    "    # Estimating SWout based on the fixed albedo value from March 2018 (0.23)\n",
    "    \n",
    "    df['SWout'] = df['SWin']*0.23\n",
    "\n",
    "    # Calculating Rn\n",
    "    df['Rn_from_drone'] = df['SWin'] - df['SWout'] + df['Lin_from_drone'] - df['Lout_from_drone']\n",
    "    \n",
    "    # Calculating temperature from lout\n",
    "    # Constants\n",
    "#     sigma = 5.670374419*10**(-8) # Stefan-Boltzmann constant\n",
    "    \n",
    "#     df['Ts_from_drone'] = ((df['Lout_from_drone']/(0.89*sigma))**0.25) - 273.15\n",
    "    \n",
    "    df['Ecosystem'] = 'PV field'\n",
    "    df['Year'] = df['DateTime'].dt.year\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    df = df[['DateTime','Season','Year','Ecosystem','H','LE','Rn_from_drone']]\n",
    "    # define mid-day\n",
    "    #df = df.loc[(df['DateTime'].dt.hour >= 11) & (df['DateTime'].dt.hour < 13)]  \n",
    "         \n",
    "    return(df)\n",
    "\n",
    "def averaging(temp):\n",
    "    \n",
    "    # define mid-day\n",
    "    temp = temp.loc[(temp['DateTime'].dt.hour >= 10) & (temp['DateTime'].dt.hour < 15)].copy() \n",
    "\n",
    "    # Make mean and std dev\n",
    "    df_means = temp.groupby(['Season','Ecosystem']).mean().reset_index()\n",
    "    df_sds   = temp.groupby(['Season','Ecosystem']).std().reset_index()\n",
    "    # rename columns\n",
    "    df_means.rename(columns={'H': 'H_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'LE': 'LE_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Rn': 'Rn_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Ta': 'Ta_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Ts': 'Ts_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'D_T': 'D_T_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'Pa': 'Pa_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'H2O': 'H2O_mean'}, inplace=True)\n",
    "    df_means.rename(columns={'rH': 'rH_mean'}, inplace=True)\n",
    "\n",
    "    df_sds.rename(columns={'H': 'H_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'LE': 'LE_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Rn': 'Rn_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Ta': 'Ta_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Ts': 'Ts_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'D_T': 'D_T_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'Pa': 'Pa_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'H2O': 'H2O_sd'}, inplace=True)\n",
    "    df_sds.rename(columns={'rH': 'rH_sd'}, inplace=True)\n",
    "    \n",
    "    merged = df_means.merge(df_sds, on=['Season','Ecosystem'])\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    merged = merged[['Season','Ecosystem','H_mean','LE_mean','Rn_mean','Ta_mean','Ts_mean','D_T_mean','Pa_mean','H2O_mean','rH_mean',\\\n",
    "                     'H_sd','LE_sd','Rn_sd','Ta_sd','Ts_sd','D_T_sd','Pa_sd','H2O_sd','rH_sd']]\n",
    "    \n",
    "    return(merged)\n",
    "\n",
    "def load_tower(fn, silent=False):\n",
    "    if (not silent): print('EC Tower')\n",
    "    temp = pd.read_csv(fn, index_col=None)\n",
    "    temp.rename({'date_mid_hour': 'DateTime'}, axis=1, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%d%b%y:%H:%M', utc=True)\n",
    "    # Remove obsolete columns\n",
    "    temp.drop(['year','date','DOY','month','weekNo','mid_hour','mmyy','Bat_V','Hum_AC'], axis=1, inplace=True)\n",
    "    if (not silent): print(\"    \", '100.0 %\\t', fn.split('/')[-1])\n",
    "    return(temp)\n",
    "\n",
    "\n",
    "# def diurnal(temp,Ecosystem,Season):\n",
    "    \n",
    "#     temp = temp.loc[(temp['Ecosystem'] == Ecosystem) & (temp['Season'] == Season)].copy()\n",
    "    \n",
    "#     # creating 'Time' column\n",
    "#     temp['Time'] = temp['DateTime'].dt.strftime('%H:%M')\n",
    "    \n",
    "#     # Keep only relevant columns\n",
    "#     temp = temp[['Time','Ecosystem','Lout']]\n",
    "    \n",
    "#     # Make mean and std dev\n",
    "#     df_means = temp.groupby(['Ecosystem','Time']).mean().reset_index()\n",
    "#     df_sds   = temp.groupby(['Ecosystem','Time']).std().reset_index()\n",
    "#     # rename columns\n",
    "#     df_means.rename(columns={'Lout': 'Lout_mean'}, inplace=True)\n",
    "#     df_means.rename(columns={'Lin': 'Lin_mean'}, inplace=True)\n",
    "#     df_means.rename(columns={'Sout': 'Sout_mean'}, inplace=True)\n",
    "#     df_means.rename(columns={'Sin': 'Sin_mean'}, inplace=True)\n",
    "#     df_means.rename(columns={'PARout': 'PARout_mean'}, inplace=True)\n",
    "#     df_means.rename(columns={'PARin': 'PARin_mean'}, inplace=True)\n",
    "    \n",
    "#     df_sds.rename(columns={'Lout': 'Lout_sd'}, inplace=True)\n",
    "#     df_sds.rename(columns={'Lin': 'Lin_sd'}, inplace=True)\n",
    "#     df_sds.rename(columns={'Sout': 'Sout_sd'}, inplace=True)\n",
    "#     df_sds.rename(columns={'Sin': 'Sin_sd'}, inplace=True)\n",
    "#     df_sds.rename(columns={'PARout': 'PARout_sd'}, inplace=True)\n",
    "#     df_sds.rename(columns={'PARin': 'PARin_sd'}, inplace=True)\n",
    "    \n",
    "#     merged = df_means.merge(df_sds, on=['Ecosystem','Time'])\n",
    "    \n",
    "#     return(merged)\n",
    "\n",
    "def pvalue_text(p):\n",
    "    if(p <= 0.001): p_text = '<.001'\n",
    "    if(p > 0.001): p_text = '<.01'\n",
    "    if(p > 0.01): p_text = '<.05'\n",
    "    if(p > 0.05): p_text = p.round(2).astype(str)\n",
    "    return(p_text)\n",
    "\n",
    "def ttest_all(temp, category, list_of_test_cols, group_col):\n",
    "    # Prepare name of categories to test against each other\n",
    "    group1 = temp[group_col].unique()[0]\n",
    "    group2 = temp[group_col].unique()[1]\n",
    "    print('Testing', group1, '&', group2)\n",
    "    \n",
    "    # Prepare df for results\n",
    "    out_df = pd.DataFrame(list(product(list_of_test_cols, temp[category].dropna().unique())), columns=['Parameter', category])\n",
    "    out_df['p'] = np.nan\n",
    "    \n",
    "    # Do t-tests for all combinations\n",
    "    for col in list_of_test_cols:\n",
    "        #print('----')\n",
    "        #print(col)\n",
    "        for cat in temp[category].dropna().unique():\n",
    "            #print(cat)\n",
    "            a = temp.loc[(temp[group_col] == group1) & (temp[category] == cat),col]\n",
    "            b = temp.loc[(temp[group_col] == group2) & (temp[category] == cat),col]\n",
    "            t = stats.ttest_ind(a, b, equal_var=False, nan_policy='omit') # Welch t-test for inequal variances\n",
    "            print(col, cat, ':', pvalue_text(t[1]))\n",
    "            # Add data to resulting df\n",
    "            out_df.loc[(out_df[category] == cat) & (out_df['Parameter'] == col), 'p'] = pvalue_text(t[1])\n",
    "    \n",
    "    return(out_df)\n",
    "\n",
    "def ttest_all2(temp, categories_to_test, list_data_cols, test_type='independent'):\n",
    "    # Prepare list of lists\n",
    "    list_of_lists = []\n",
    "    for cat_i, cat in enumerate(categories_to_test):\n",
    "        sub_categories = list(temp[cat].unique())\n",
    "        list_of_lists.append(sub_categories)\n",
    "    print('All categories:', list_of_lists)\n",
    "    \n",
    "    # Count number of categories\n",
    "    cat_count = len(categories_to_test)\n",
    "    list_of_dfs = []\n",
    "    \n",
    "    # Go through the list of all data columns\n",
    "    for data_col in list_data_cols:\n",
    "        print(\"Testing data column: \", data_col)\n",
    "        \n",
    "        # Prepare empty list of lists to fill\n",
    "        out_list = []\n",
    "        # List all combinations, and go through\n",
    "        for i in list(combinations( list(product(*list_of_lists)) , 2)):\n",
    "            # If no x-1 elements (for 3 categories, that's 2) overlaps, skip\n",
    "            # This makes sure not to test combinations where everything is different\n",
    "            # (e.g. Autumn Pines Hamsin vs Spring Maquis Normal)\n",
    "            if(sum([j in i[0] for j in i[1]]) < (cat_count-1)):\n",
    "                continue\n",
    "            #print(i)  # DEBUG\n",
    "            # Prepare row to append data\n",
    "            row_list = []\n",
    "            a_conditions = []\n",
    "            b_conditions = []\n",
    "            # Check which elements are the same in each pair\n",
    "            for j in range(cat_count):\n",
    "                if(i[0][j] == i[1][j]):\n",
    "                    #print('Identical columns:', i[0][j]) # DEBUG\n",
    "                    row_list.append(i[0][j])\n",
    "                else:\n",
    "                    #print('Column to test:', categories_to_test[j]) # DEBUG\n",
    "                    row_list.append('')\n",
    "                # Create list of conditions\n",
    "                a_conditions.append(temp[categories_to_test[j]] == i[0][j])\n",
    "                b_conditions.append(temp[categories_to_test[j]] == i[1][j])\n",
    "            # Create the text of which 2 variables are being tested against each other\n",
    "            test_str = list(set(i[0]) - set(i[1]))[0] + ' vs. ' + list(set(i[1]) - set(i[0]))[0]\n",
    "            row_list.append(test_str)\n",
    "            # Prepare t-test\n",
    "            a = temp.loc[reduce(np.logical_and, a_conditions), data_col]\n",
    "            b = temp.loc[reduce(np.logical_and, b_conditions), data_col]\n",
    "            if(test_type == 'independent'):\n",
    "                t = stats.ttest_ind(a, b, equal_var=False, nan_policy='omit') # Welch t-test for inequal variances\n",
    "            else:\n",
    "                t = stats.ttest_rel(a, b, nan_policy='omit') # Paired t-test\n",
    "            #row_list.append(t[1]) # Full P value\n",
    "            row_list.append(pvalue_text(t[1])) # P value as text\n",
    "            # Add p values to final output\n",
    "            out_list.append(row_list)\n",
    "    \n",
    "        # Column names\n",
    "        colnames = categories_to_test + ['Test','P_'+data_col]\n",
    "        out_df = pd.DataFrame(out_list, columns=colnames)\n",
    "        list_of_dfs.append(out_df)\n",
    "    \n",
    "    # Finally merge all\n",
    "    final_df = reduce(lambda df1,df2: pd.merge(df1,df2, on=categories_to_test + ['Test']), list_of_dfs)\n",
    "    print('Done...')\n",
    "    \n",
    "    return(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate saturation vapour pressure from pressure and temperature\n",
    "# - 2 methods are available. Jones uses air pressure, Campbell & Norman do not\n",
    "def calculate_es(T_C, P_Pa):\n",
    "    # Jones p.348 (appendix 4)\n",
    "    #es = (1.00072+(10**(-7)*P_Pa*(0.032+5.9*10**(-6)*T_C**2))) * (611.21*np.exp( (18.678-(T_C/234.5))*T_C/(257.14+T_C) ))\n",
    "\n",
    "    # Eddypro manual: https://www.licor.com/env/support/EddyPro/topics/calculate-micromet-variables.html\n",
    "    # Campbell & Norman (1998)\n",
    "    T_K = T_C + 273.15\n",
    "    es = T_K**(-8.2) * np.exp(77.345 + 0.0057*T_K - 7235 * T_K**(-1))\n",
    "    return(es)\n",
    "\n",
    "# Converts water concentration [mmol.mol] to RH [%]\n",
    "def convert_mmol_RH(T_C, h2o_mmol_mol, P_Pa):\n",
    "    \n",
    "    T_K = T_C + 273.15\n",
    "    #es = calculate_es(T_C, P_Pa)\n",
    "    #RH <- 0.263*P_Pa*((h2o_mmol_mol*18.02/28.97)/1000)*np.exp(17.67*(T_C)/(T_K-29.65))**(-1)\n",
    "    #RH = 100 if (RH > 100) else RH\n",
    "    #RH = np.nan if (RH < 5) else RH\n",
    "\n",
    "    # From Eddypro manual: https://www.licor.com/env/support/EddyPro/topics/calculate-micromet-variables.html\n",
    "    R  = 8.314463                  # Ideal gas constant (J K-1 mol-1)\n",
    "    M_d   = 0.02897                # molecular weights of dry air (kg mol-1)\n",
    "    M_h2o = 0.01802                # molecular weights of water vapour (kg mol-1)\n",
    "    R_h2o = R / M_h2o              # Water vapor gas constant (J K-1 mol-1)\n",
    "    es = calculate_es(T_C, P_Pa)   # Water vapor partial pressure at saturation (Pa)\n",
    "    P_d = P_Pa - es                # Dry air partial pressure (P_d, P_a)\n",
    "    rho_d = P_d / (R / M_d * T_K)  # Dry air mass density (rho_d, kg m-3)\n",
    "    v_d = M_d / rho_d              # Dry air molar volume (vd, m3 mol-1)\n",
    "    v_a = v_d * P_d/P_Pa           # Air molar volume (vd, m3mol-1) \n",
    "    rho_h2o = h2o_mmol_mol/1000 * M_h2o / v_a # Water vapor mole fraction\n",
    "    e  = rho_h2o * R_h2o * T_K     # Water vapor partial pressure (Pa) \n",
    "    RH = e/es * 100                # RH (%)\n",
    "    return(RH)\n",
    "\n",
    "# Density of dry air\n",
    "# - https://en.wikipedia.org/wiki/Density_of_air\n",
    "def calculate_rho_dry_air(T_C, P_Pa):\n",
    "    # Constants\n",
    "    R_dry_air = 287.058     # [J/(kg·K)] Specific gas const dry air\n",
    "    # Calculations\n",
    "    T_K = T_C + 273.15\n",
    "    rho_dry_air = P_Pa / (R_dry_air * T_K) # Density of dry air (use for approximation)\n",
    "    return(rho_dry_air)\n",
    "\n",
    "# Density of moist air\n",
    "def calculate_rho_moist_air(T_C, h2o_mmol_mol, P_Pa):\n",
    "    # Temperature in K\n",
    "    T_K = T_C + 273.15\n",
    "\n",
    "    # Preparations\n",
    "    R     = 8.314463             # Ideal gas constant (J K-1 mol-1)\n",
    "    M_d   = 0.02897              # molecular weights of dry air (kg mol-1)\n",
    "    M_h2o = 0.01802              # molecular weights of water vapour (kg mol-1)\n",
    "    es = calculate_es(T_C, P_Pa) # Saturation vapour pressure (Pa)\n",
    "    P_d = P_Pa - es              # Dry air partial pressure (P_d, P_a)\n",
    "    rho_d = P_d / (R / M_d * T_K) # Dry air mass density (rho_d, kg m-3)\n",
    "    v_d = M_d / rho_d            # Dry air molar volume (vd, m3 mol-1)\n",
    "    v_a = v_d * P_d/P_Pa         # Air molar volume (vd, m3mol-1) \n",
    "    rho_h2o = h2o_mmol_mol/1000 * M_h2o / v_a # Water vapor mole fraction\n",
    "\n",
    "    # Moist air mass density (ρa, kg m-3) \n",
    "    rho_air = rho_d + rho_h2o\n",
    "\n",
    "    return(rho_air)\n",
    "\n",
    "# Dry air heat capacity at constant pressure\n",
    "# cp_d in [J kg-1 K-1]\n",
    " # https://www.licor.com/env/support/EddyPro/topics/calculate-micromet-variables.html\n",
    "def calculate_cp_dry_air(T_C):\n",
    "    cp = 1005 + ((T_C + 23.12)**2)/3364\n",
    "    return(cp)\n",
    "\n",
    "# Specific heat capacity of moist air at constant pressure\n",
    "# cp_m in [J kg-1 K-1]\n",
    "# https://www.licor.com/env/support/EddyPro/topics/calculate-micromet-variables.html\n",
    "def calculate_cp_moist_air(T_C, h2o_mmol_mol, P_Pa):\n",
    "    # Temperature in K\n",
    "    T_K = T_C + 273.15\n",
    "\n",
    "    # RH\n",
    "    RH = convert_mmol_RH(T_C, h2o_mmol_mol, P_Pa)\n",
    "\n",
    "    # Water vapor heat capacity at constant pressure (cp_h2o, J kg-1 K-1)\n",
    "    cp_h2o = 1859 + 0.13*RH + (0.193 + 5.6*10**(-3) * RH)*T_C + (10**(-3) + 5 * 10**(-5)*RH)*T_C**2\n",
    "\n",
    "    # Preparations\n",
    "    R     = 8.314463             # Ideal gas constant (J K-1 mol-1)\n",
    "    M_d   = 0.02897              # molecular weights of dry air (kg mol-1)\n",
    "    M_h2o = 0.01802              # molecular weights of water vapour (kg mol-1)\n",
    "    es = calculate_es(T_C, P_Pa) # Saturation vapour pressure (Pa)\n",
    "    P_d = P_Pa - es              # Dry air partial pressure (P_d, P_a)\n",
    "    rho_d = P_d / (R / M_d * T_K) # Dry air mass density (rho_d, kg m-3)\n",
    "    v_d = M_d / rho_d            # Dry air molar volume (vd, m3 mol-1)\n",
    "    v_a = v_d * P_d/P_Pa         # Air molar volume (vd, m3mol-1) \n",
    "    rho_h2o = h2o_mmol_mol/1000 * M_h2o / v_a # Water vapor mole fraction\n",
    "\n",
    "    # Moist air mass density (ρa, kg m-3) \n",
    "    rho_air = rho_d + rho_h2o\n",
    "\n",
    "    # Specific humidity (Q, kg kg-1) \n",
    "    Q = rho_h2o / rho_air\n",
    "\n",
    "    # cp_moist\n",
    "    cp = calculate_cp_dry_air(T_C) * (1-Q) + cp_h2o * Q\n",
    "    return(cp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Rafael Ketura Desert Background July 2019 calibration applyied storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Ketura Desert Background March 2018 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Ketura Desert Background October 2018 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Ketura Solar Field July 2019 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Ketura Solar Field March 2018 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Ketura Solar Field October 2018 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Yatir Yatir Desert August 2013 storagek analysis SWLWcorr.csv\n",
      "Loading Rafael Yatir Yatir Desert August 2015 storagek analysis SWLWcorr.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Season</th>\n",
       "      <th>Ecosystem</th>\n",
       "      <th>Lin</th>\n",
       "      <th>Lout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-09 20:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Desert background</td>\n",
       "      <td>407.393005</td>\n",
       "      <td>503.072601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 21:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Desert background</td>\n",
       "      <td>400.308990</td>\n",
       "      <td>497.234985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-09 21:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Desert background</td>\n",
       "      <td>396.226013</td>\n",
       "      <td>492.450989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-09 22:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Desert background</td>\n",
       "      <td>393.476013</td>\n",
       "      <td>488.117004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-09 22:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Desert background</td>\n",
       "      <td>391.584991</td>\n",
       "      <td>484.428009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>2015-08-29 23:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>329.941986</td>\n",
       "      <td>417.607605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>2015-08-29 23:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>330.522003</td>\n",
       "      <td>415.586853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>2015-08-30 00:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>331.742004</td>\n",
       "      <td>415.492798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2015-08-30 00:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>332.226990</td>\n",
       "      <td>412.988922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2015-08-30 01:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>333.697998</td>\n",
       "      <td>411.820831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2877 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DateTime  Season          Ecosystem         Lin  \\\n",
       "0    2019-07-09 20:30:00+00:00  Summer  Desert background  407.393005   \n",
       "1    2019-07-09 21:00:00+00:00  Summer  Desert background  400.308990   \n",
       "2    2019-07-09 21:30:00+00:00  Summer  Desert background  396.226013   \n",
       "3    2019-07-09 22:00:00+00:00  Summer  Desert background  393.476013   \n",
       "4    2019-07-09 22:30:00+00:00  Summer  Desert background  391.584991   \n",
       "...                        ...     ...                ...         ...   \n",
       "2872 2015-08-29 23:00:00+00:00  Summer       Yatir desert  329.941986   \n",
       "2873 2015-08-29 23:30:00+00:00  Summer       Yatir desert  330.522003   \n",
       "2874 2015-08-30 00:00:00+00:00  Summer       Yatir desert  331.742004   \n",
       "2875 2015-08-30 00:30:00+00:00  Summer       Yatir desert  332.226990   \n",
       "2876 2015-08-30 01:00:00+00:00  Summer       Yatir desert  333.697998   \n",
       "\n",
       "            Lout  \n",
       "0     503.072601  \n",
       "1     497.234985  \n",
       "2     492.450989  \n",
       "3     488.117004  \n",
       "4     484.428009  \n",
       "...          ...  \n",
       "2872  417.607605  \n",
       "2873  415.586853  \n",
       "2874  415.492798  \n",
       "2875  412.988922  \n",
       "2876  411.820831  \n",
       "\n",
       "[2877 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Season</th>\n",
       "      <th>Ecosystem</th>\n",
       "      <th>Lin</th>\n",
       "      <th>Lout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>2013-08-21 14:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>378.914886</td>\n",
       "      <td>548.832336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>2013-08-21 15:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>374.091278</td>\n",
       "      <td>537.297424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>2013-08-21 15:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>373.338226</td>\n",
       "      <td>525.480835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>2013-08-21 16:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>369.784271</td>\n",
       "      <td>508.860809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>2013-08-21 16:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>365.081665</td>\n",
       "      <td>494.966644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>2015-08-29 23:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>329.941986</td>\n",
       "      <td>417.607605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>2015-08-29 23:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>330.522003</td>\n",
       "      <td>415.586853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>2015-08-30 00:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>331.742004</td>\n",
       "      <td>415.492798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2015-08-30 00:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>332.226990</td>\n",
       "      <td>412.988922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2015-08-30 01:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir desert</td>\n",
       "      <td>333.697998</td>\n",
       "      <td>411.820831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DateTime  Season     Ecosystem         Lin        Lout\n",
       "1846 2013-08-21 14:30:00+00:00  Summer  Yatir desert  378.914886  548.832336\n",
       "1847 2013-08-21 15:00:00+00:00  Summer  Yatir desert  374.091278  537.297424\n",
       "1848 2013-08-21 15:30:00+00:00  Summer  Yatir desert  373.338226  525.480835\n",
       "1849 2013-08-21 16:00:00+00:00  Summer  Yatir desert  369.784271  508.860809\n",
       "1850 2013-08-21 16:30:00+00:00  Summer  Yatir desert  365.081665  494.966644\n",
       "...                        ...     ...           ...         ...         ...\n",
       "2872 2015-08-29 23:00:00+00:00  Summer  Yatir desert  329.941986  417.607605\n",
       "2873 2015-08-29 23:30:00+00:00  Summer  Yatir desert  330.522003  415.586853\n",
       "2874 2015-08-30 00:00:00+00:00  Summer  Yatir desert  331.742004  415.492798\n",
       "2875 2015-08-30 00:30:00+00:00  Summer  Yatir desert  332.226990  412.988922\n",
       "2876 2015-08-30 01:00:00+00:00  Summer  Yatir desert  333.697998  411.820831\n",
       "\n",
       "[1031 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mast_df = load_all_data(input_path)\n",
    "\n",
    "mast_df = mast_df.loc[(mast_df['Ecosystem'] == 'Yatir desert')].copy()\n",
    "\n",
    "display(mast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223371932018459524)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbPalette = [\"#DE090F\",\"#2D09DE\", \"#DE090F\", \"#02000B\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "mast_df = mast_df.loc[(mast_df['DateTime'].dt.year == '2015')].copy()\n",
    "\n",
    "plt = ggplot(mast_df)\n",
    "plt = plt + geom_line(aes(x='DateTime', y='Lin'),size=1.5)\n",
    "#plt = plt + geom_line(aes(x='DateTime', y='Lout'),size=1.5)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=1,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "#plt = plt + coord_cartesian(ylim=(-0.1, 0.9))\n",
    "#plt = plt + scale_y_continuous(breaks=np.arange(-0.1, 1, 0.1))\n",
    "#plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Yatir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC Tower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafas\\Miniconda3\\envs\\analysis\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3337: DtypeWarning: Columns (9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     100.0 %\t Yatir_2000-2020.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Season</th>\n",
       "      <th>Ecosystem</th>\n",
       "      <th>Lin</th>\n",
       "      <th>Lout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265872</th>\n",
       "      <td>2015-07-01 00:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>308.399994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265873</th>\n",
       "      <td>2015-07-01 00:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>308.200012</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265874</th>\n",
       "      <td>2015-07-01 01:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>307.399994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265875</th>\n",
       "      <td>2015-07-01 01:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>307.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265876</th>\n",
       "      <td>2015-07-01 02:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>307.299988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355051</th>\n",
       "      <td>2020-07-31 21:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>344.500000</td>\n",
       "      <td>440.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355052</th>\n",
       "      <td>2020-07-31 22:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>341.700012</td>\n",
       "      <td>438.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355053</th>\n",
       "      <td>2020-07-31 22:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>341.100006</td>\n",
       "      <td>436.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355054</th>\n",
       "      <td>2020-07-31 23:00:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>436.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355055</th>\n",
       "      <td>2020-07-31 23:30:00+00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Yatir</td>\n",
       "      <td>342.700012</td>\n",
       "      <td>435.399994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8928 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DateTime  Season Ecosystem         Lin        Lout\n",
       "265872 2015-07-01 00:00:00+00:00  Summer     Yatir  308.399994         NaN\n",
       "265873 2015-07-01 00:30:00+00:00  Summer     Yatir  308.200012         NaN\n",
       "265874 2015-07-01 01:00:00+00:00  Summer     Yatir  307.399994         NaN\n",
       "265875 2015-07-01 01:30:00+00:00  Summer     Yatir  307.500000         NaN\n",
       "265876 2015-07-01 02:00:00+00:00  Summer     Yatir  307.299988         NaN\n",
       "...                          ...     ...       ...         ...         ...\n",
       "355051 2020-07-31 21:30:00+00:00  Summer     Yatir  344.500000  440.899994\n",
       "355052 2020-07-31 22:00:00+00:00  Summer     Yatir  341.700012  438.299988\n",
       "355053 2020-07-31 22:30:00+00:00  Summer     Yatir  341.100006  436.799988\n",
       "355054 2020-07-31 23:00:00+00:00  Summer     Yatir  341.000000  436.500000\n",
       "355055 2020-07-31 23:30:00+00:00  Summer     Yatir  342.700012  435.399994\n",
       "\n",
       "[8928 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    }
   ],
   "source": [
    "yatir_df = load_tower(input_path + 'Yatir_2000-2020.csv')\n",
    "yatir_df = yatir_df.loc[(yatir_df['DateTime'].dt.year >= 2015)].copy()\n",
    "yatir_df = yatir_df.loc[(yatir_df['DateTime'].dt.month == 7)].copy()\n",
    "yatir_df['DateTime'] = yatir_df['DateTime'] - pd.Timedelta(minutes=15)\n",
    "\n",
    "# Rename\n",
    "yatir_df.rename(columns={'S_top_atm(CM21_IV)_Wm-2': 'Sin'}, inplace=True)\n",
    "yatir_df.rename(columns={'S_top_eco(CM21_III)_Wm-2': 'Sout'}, inplace=True)\n",
    "yatir_df.rename(columns={'PAR_top_atm(IV)_umol_m-2s-1': 'PARin'}, inplace=True)\n",
    "yatir_df.rename(columns={'PAR_top_eco(III)_umol_m-2s-1': 'PARout'}, inplace=True)\n",
    "yatir_df.rename(columns={'L_top_atm(PIR_IV)_Wm-2': 'Lin'}, inplace=True)\n",
    "yatir_df.rename(columns={'L_top_eco(PIR_III)_Wm-2': 'Lout'}, inplace=True)\n",
    "yatir_df.rename(columns={'Fc_Cor_umol_m-2s-1': 'NEE'}, inplace=True)\n",
    "yatir_df.rename(columns={'LE_Wm-2_Avg': 'LE'}, inplace=True)\n",
    "yatir_df.rename(columns={'H_Wm-2': 'H'}, inplace=True)\n",
    "yatir_df.rename(columns={'H2O_Con_mmol_mol-1': 'H2O'}, inplace=True)\n",
    "yatir_df.rename(columns={'AirPress_Pa': 'Pa'}, inplace=True)\n",
    "# yatir_df.rename(columns={'date_mid_hour': 'DateTime'}, inplace=True)\n",
    "\n",
    "# yatir_df['DateTime'] = pd.to_datetime(yatir_df['DateTime'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "\n",
    "# Convert columns to float\n",
    "yatir_df['Sin']  = pd.to_numeric(yatir_df['Sin'], downcast=\"float\")\n",
    "yatir_df['Sout']  = pd.to_numeric(yatir_df['Sout'], downcast=\"float\")\n",
    "yatir_df['PARin']  = pd.to_numeric(yatir_df['PARin'], downcast=\"float\")\n",
    "yatir_df['PARout']  = pd.to_numeric(yatir_df['PARout'], downcast=\"float\")\n",
    "yatir_df['Lin']  = pd.to_numeric(yatir_df['Lin'], downcast=\"float\")\n",
    "yatir_df['Lout']  = pd.to_numeric(yatir_df['Lout'], downcast=\"float\")\n",
    "yatir_df['NEE']  = pd.to_numeric(yatir_df['NEE'], downcast=\"float\")\n",
    "yatir_df['LE']  = pd.to_numeric(yatir_df['LE'], downcast=\"float\")\n",
    "yatir_df['H']  = pd.to_numeric(yatir_df['H'], downcast=\"float\")\n",
    "yatir_df['H2O']  = pd.to_numeric(yatir_df['H2O'], downcast=\"float\")\n",
    "yatir_df['Pa']  = pd.to_numeric(yatir_df['Pa'], downcast=\"float\")\n",
    "    \n",
    "yatir_df['albedo'] = yatir_df['Sout']/yatir_df['Sin']\n",
    "yatir_df['Rn'] = yatir_df['Sin'] - yatir_df['Sout'] + yatir_df['Lin'] - yatir_df['Lout']\n",
    "\n",
    "\n",
    "# Make air temperature mean of top of tower, according to the system used in \n",
    "def mean_tower_temp(temp, T_col_list):\n",
    "    # Prepare data\n",
    "    temp = temp[['DateTime'] + T_col_list].copy() # timestamp added for debugging only\n",
    "    # Calculate the mean\n",
    "    temp['T_mean'] = temp[T_col_list].mean(axis=1)\n",
    "    # Check each column to see if the difference from the mean is > 2°C. If so, remove\n",
    "    for column in T_col_list:\n",
    "        temp.loc[np.abs(temp[column] - temp['T_mean']) > 2, column] = np.nan\n",
    "    # Re-calculate the mean from the remaining data\n",
    "    temp['T_mean'] = temp[T_col_list].mean(axis=1)\n",
    "        \n",
    "    return(temp['T_mean'])\n",
    "\n",
    "# Make the mean air temperature,\n",
    "# remove any value where one of them is more than 2°C off from the mean,\n",
    "# and then calculate the mean again from the remaining data\n",
    "yatir_df['Ta'] = mean_tower_temp(yatir_df, ['T 15m Vaisala_C', 'Prof_Tc_13m_C', 'Prof_Tc_15m_C', 'T_PIR_III_K'])\n",
    "\n",
    "# Calculating temperature from lout\n",
    "# Constants\n",
    "sigma = 5.670374419*10**(-8) # Stefan-Boltzmann constant\n",
    "emissivity_forest = 0.873  # Thakur 2021\n",
    "\n",
    "yatir_df['Ts'] = ((yatir_df['Lout']/(emissivity_forest*sigma))**0.25) - 273.15\n",
    "\n",
    "yatir_df['D_T'] = yatir_df['Ts'] - yatir_df['Ta']\n",
    "\n",
    "yatir_df['Season'] = 'Summer'\n",
    "yatir_df['Ecosystem'] = 'Yatir'\n",
    "\n",
    "# Keep only relevant columns\n",
    "yatir_df = yatir_df[['DateTime','Season','Ecosystem','Lin','Lout']]\n",
    "\n",
    "display(yatir_df)\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Yatir & Ktura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Season</th>\n",
       "      <th>Ecosystem</th>\n",
       "      <th>Lin_x</th>\n",
       "      <th>Lout_x</th>\n",
       "      <th>Lin_y</th>\n",
       "      <th>Lout_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DateTime, Season, Ecosystem, Lin_x, Lout_x, Lin_y, Lout_y]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#final_df = pd.concat([mast_df, yatir_df])\n",
    "final_df = mast_df.merge(yatir_df, on=['DateTime','Season','Ecosystem'])\n",
    "\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ecosystem</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Desert background</th>\n",
       "      <th>PV field</th>\n",
       "      <th>Yatir</th>\n",
       "      <th>Yatir desert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D_T</td>\n",
       "      <td>17.9 (1.1)</td>\n",
       "      <td>22.2 (2.4)</td>\n",
       "      <td>14.2 (0.9)</td>\n",
       "      <td>20.6 (1.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>201 (50)</td>\n",
       "      <td>347 (85)</td>\n",
       "      <td>531 (100)</td>\n",
       "      <td>228 (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LE</td>\n",
       "      <td>31 (21)</td>\n",
       "      <td>36 (23)</td>\n",
       "      <td>39 (50)</td>\n",
       "      <td>34 (42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rn</td>\n",
       "      <td>410 (35)</td>\n",
       "      <td>535 (51)</td>\n",
       "      <td>671 (84)</td>\n",
       "      <td>452 (71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ta</td>\n",
       "      <td>37.2 (3.0)</td>\n",
       "      <td>36.8 (3.6)</td>\n",
       "      <td>31.1 (2.4)</td>\n",
       "      <td>29.3 (1.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ts</td>\n",
       "      <td>55.1 (3.6)</td>\n",
       "      <td>59.4 (2.1)</td>\n",
       "      <td>45.4 (2.5)</td>\n",
       "      <td>49.9 (2.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rH</td>\n",
       "      <td>100 (24)</td>\n",
       "      <td>73 (25)</td>\n",
       "      <td>29 (6)</td>\n",
       "      <td>102 (30)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ecosystem Parameter Desert background    PV field       Yatir Yatir desert\n",
       "0               D_T        17.9 (1.1)  22.2 (2.4)  14.2 (0.9)   20.6 (1.9)\n",
       "1                 H          201 (50)    347 (85)   531 (100)     228 (50)\n",
       "2                LE           31 (21)     36 (23)     39 (50)      34 (42)\n",
       "3                Rn          410 (35)    535 (51)    671 (84)     452 (71)\n",
       "4                Ta        37.2 (3.0)  36.8 (3.6)  31.1 (2.4)   29.3 (1.9)\n",
       "5                Ts        55.1 (3.6)  59.4 (2.1)  45.4 (2.5)   49.9 (2.4)\n",
       "6                rH          100 (24)     73 (25)      29 (6)     102 (30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_df = averaging(final_df)\n",
    "#display(mean_df)\n",
    "\n",
    "# Create a text of summarised values (mean + stddev)\n",
    "mean_df['Rn'] = mean_df['Rn_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['Rn_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['H'] = mean_df['H_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['H_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['LE'] = mean_df['LE_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['LE_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "mean_df['Ta'] = mean_df['Ta_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['Ta_sd'].round(1).astype(str) + ')'\n",
    "mean_df['Ts'] = mean_df['Ts_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['Ts_sd'].round(1).astype(str) + ')'\n",
    "mean_df['D_T'] = mean_df['D_T_mean'].astype(float).round(1).astype(str) + ' (' + mean_df['D_T_sd'].round(1).astype(str) + ')'\n",
    "mean_df['rH'] = mean_df['rH_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['rH_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "#mean_df['Pa'] = mean_df['Pa_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['Pa_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "#mean_df['H2O'] = mean_df['H2O_mean'].astype(float).round(0).astype(int).astype(str) + ' (' + mean_df['H2O_sd'].astype(float).round(0).astype(int).astype(str) + ')'\n",
    "\n",
    "# Remove the original values\n",
    "mean_df.drop(['H_mean','H_sd','LE_mean','LE_sd','Rn_mean','Rn_sd','Ta_mean','Ta_sd','Ts_mean','Ts_sd','D_T_mean','D_T_sd','Pa_mean',\\\n",
    "              'Pa_sd','H2O_mean','H2O_sd','rH_mean','rH_sd'], axis=1, inplace=True)\n",
    "#display(mean_df)\n",
    "\n",
    "# Convert to long format\n",
    "out_df = mean_df.pivot(index='Season', columns='Ecosystem').stack(level=[0])\n",
    "out_df.reset_index(inplace=True)\n",
    "out_df.drop(['Season'], axis=1, inplace=True)\n",
    "out_df.rename(columns={'level_1': 'Parameter'}, inplace=True)\n",
    "display(out_df)\n",
    "\n",
    "out_df.to_latex(output_path + 'Ketura_Science_resistance_new.tex', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean_yatir_df = averaging(yatir_df).round(2)\n",
    "\n",
    "# Move Season to the front\n",
    "col = mean_yatir_df.pop('Season')\n",
    "mean_yatir_df.insert(0, col.name, col)\n",
    "# Create a text of summarised values (mean + stddev)\n",
    "mean_yatir_df['H'] = mean_yatir_df['H_mean'].astype(int).astype(str) + ' (' + mean_yatir_df['H_sd'].astype(int).astype(str) + ')'\n",
    "mean_yatir_df['LE'] = mean_yatir_df['LE_mean'].astype(int).astype(str) + ' (' + mean_yatir_df['LE_sd'].astype(int).astype(str) + ')'\n",
    "mean_yatir_df['Rn'] = mean_yatir_df['Rn_mean'].astype(int).astype(str) + ' (' + mean_yatir_df['Rn_sd'].astype(int).astype(str) + ')'\n",
    "mean_yatir_df['Ta'] = mean_yatir_df['Ta_mean'].round(1).astype(str) + ' (' + mean_yatir_df['Ta_sd'].round(1).astype(str) + ')'\n",
    "mean_yatir_df['Ts'] = mean_yatir_df['Ts_mean'].round(1).astype(str) + ' (' + mean_yatir_df['Ts_sd'].round(1).astype(str) + ')'\n",
    "mean_yatir_df['D_T'] = mean_yatir_df['D_T_mean'].round(1).astype(str) + ' (' + mean_yatir_df['D_T_sd'].round(1).astype(str) + ')'\n",
    "mean_yatir_df['Pa'] = mean_yatir_df['Pa_mean'].astype(int).astype(str) + ' (' + mean_yatir_df['Pa_sd'].astype(int).astype(str) + ')'\n",
    "\n",
    "\n",
    "# Remove the original values\n",
    "mean_yatir_df = mean_yatir_df[['Season','Ecosystem','H','LE','Rn','Ta','Ts','D_T','Pa']]\n",
    "# Convert to wide format\n",
    "#mean_df = mean_df.pivot(index='Ecosystem', columns='Season').stack(level=[0])\n",
    "\n",
    "#mean_yatir_df.to_latex(output_path + 'Ketura_Science_resistance_new.tex', index=True)\n",
    "\n",
    "display(mean_yatir_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Ketura and Yatir dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_yatir_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6dce8b38c042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_yatir_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_yatir_df' is not defined"
     ]
    }
   ],
   "source": [
    "all_df = pd.concat([mean_df, mean_yatir_df])\n",
    "\n",
    "display(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat capacity of air [J kg-1 K-1]\n",
    "all_df['cp'] = calculate_cp_moist_air(all_df['Ta'], all_df['WATER'], all_df['Pa'])\n",
    "\n",
    "# Density of air [kg m-3]\n",
    "all_df['rho'] = calculate_rho_moist_air(all_df['Ta'], all_df['WATER'], all_df['Pa']) \n",
    "\n",
    "# Calculate resistance [s m-1]\n",
    "all_df['rH'] = all_df['rho'] * all_df['cp'] * all_df['D_T'] / all_df['H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-tests seasonal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = ttest_all2(all_df.loc[~all_df['Season'].isna()], ['Season', 'Ecosystem'], ['Sin','Sout','Lin','Lout','PARin','PARout'])\n",
    "display(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare table\n",
    "final_df = mean_df.pivot(index='Season', columns='Ecosystem').stack(level=[0])\n",
    "display(final_df)\n",
    "\n",
    "final_df = final_df.reset_index()\n",
    "#final_df['P'] = ''\n",
    "final_df.rename(columns={'level_1': 'Parameter'}, inplace=True)\n",
    "\n",
    "\n",
    "p_df = ttest_all(all_df, 'Season', ['Sin','Sout','Lin','Lout','PARin','PARout'], 'Ecosystem')\n",
    "\n",
    "final_df = final_df.merge(p_df, on = ['Parameter', 'Season'], how='left').copy()\n",
    "\n",
    "display(final_df)\n",
    "final_df.to_latex(output_path + 'Ketura_radiative_fluxes_new.tex', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-tests diurnal each half-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['Time'] = all_df['DateTime'].dt.strftime('%H:%M')\n",
    "\n",
    "# Make mean and std dev\n",
    "df_means = all_df.groupby(['Ecosystem','Season','Time']).mean().reset_index()\n",
    "df_sds   = all_df.groupby(['Ecosystem','Season','Time']).std().reset_index()\n",
    "# rename columns\n",
    "df_means.rename(columns={'Lout': 'Lout_mean'}, inplace=True)\n",
    "df_means.rename(columns={'Lin': 'Lin_mean'}, inplace=True)\n",
    "df_means.rename(columns={'Sout': 'Sout_mean'}, inplace=True)\n",
    "df_means.rename(columns={'Sin': 'Sin_mean'}, inplace=True)\n",
    "df_means.rename(columns={'PARout': 'PARout_mean'}, inplace=True)\n",
    "df_means.rename(columns={'PARin': 'PARin_mean'}, inplace=True)\n",
    "    \n",
    "df_sds.rename(columns={'Lout': 'Lout_sd'}, inplace=True)\n",
    "df_sds.rename(columns={'Lin': 'Lin_sd'}, inplace=True)\n",
    "df_sds.rename(columns={'Sout': 'Sout_sd'}, inplace=True)\n",
    "df_sds.rename(columns={'Sin': 'Sin_sd'}, inplace=True)\n",
    "df_sds.rename(columns={'PARout': 'PARout_sd'}, inplace=True)\n",
    "df_sds.rename(columns={'PARin': 'PARin_sd'}, inplace=True)\n",
    "\n",
    "\n",
    "all_df_diurnal = df_means.merge(df_sds, on=['Ecosystem','Season','Time'])\n",
    "all_df_diurnal['Season'] = pd.Categorical(all_df_diurnal['Season'], ordered=True, categories=['Spring','Summer','Autumn'])\n",
    "# Remove the original values\n",
    "all_df_diurnal.drop(['PARout_albedo_derived_x','Lout_from_drone_x','Sout_albedo_derived_x','PARout_albedo_derived_y','Lout_from_drone_y','Sout_albedo_derived_y'], axis=1, inplace=True)\n",
    "\n",
    "display (all_df_diurnal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lout night values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Autumn, night: P =', pvalue_text(t[1]))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Spring, night: P =', np.round(t[1],2))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Summer, night: P =', pvalue_text(t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lin night values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Autumn, night: P =', pvalue_text(t[1]))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Spring, night: P =', np.round(t[1],2))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '20:00') | (all_df_diurnal['Time'] < '06:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Summer, night: P =', pvalue_text(t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lout mid-day values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "#t = stats.ttest_ind(a, b, equal_var=False, nan_policy='omit') # Welch t-test for inequal variances\n",
    "print('Autumn, mid-day: P =', pvalue_text(t[1]))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Spring, mid-day: P =', np.round(t[1],2))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lout_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "#t = stats.ttest_ind(a, b, equal_var=False, nan_policy='omit') # Welch t-test for inequal variances\n",
    "print('Summer, mid-day: P =', pvalue_text(t[1]))\n",
    "\n",
    "display(all_df_diurnal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L_{in}$ day values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Autumn') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Autumn, night: P =', pvalue_text(t[1]))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Spring') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Spring, night: P =', np.round(t[1],2))\n",
    "\n",
    "a = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'Desert background') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "b = all_df_diurnal.loc[(all_df_diurnal['Ecosystem'] == 'PV field') & (all_df_diurnal['Season'] == 'Summer') & ((all_df_diurnal['Time'] >= '10:00') & (all_df_diurnal['Time'] < '15:00')),'Lin_mean']\n",
    "t = stats.ttest_rel(a, b, nan_policy='omit')\n",
    "print('Summer, night: P =', pvalue_text(t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='Lout_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='Lout_mean - Lout_sd', ymax='Lout_mean + Lout_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$L_{out}\\; (W \\; m^{-2}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'lout_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'lout_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='Lin_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='Lin_mean - Lin_sd', ymax='Lin_mean + Lin_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$L_{in}\\; (W \\; m^{-2}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'lin_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'lin_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='Sin_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='Sin_mean - Sin_sd', ymax='Sin_mean + Sin_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$S_{in}\\; (W \\; m^{-2}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'Sin_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'Sin_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='Sout_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='Sout_mean - Sout_sd', ymax='Sout_mean + Sout_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$S_{out}\\; (W \\; m^{-2}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'Sout_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'Sout_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='PARin_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='PARin_mean - Sin_sd', ymax='PARin_mean + PARin_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$PAR_{in}\\; (\\mu mol \\; m^{-2} \\; s^{-1}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'PARin_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'PARin_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbPalette = [\"#02000B\", \"#2D09DE\", \"#DE090F\", \"#80ff80\", \"#c2c2d6\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "# Convert the times back to a “fake” timestamp:\n",
    "all_df_diurnal['timestamp2'] = pd.to_datetime(all_df_diurnal['Time'], utc=True)\n",
    "\n",
    "plt = ggplot(all_df_diurnal)\n",
    "plt = plt + geom_line(aes(x='timestamp2', y='PARout_mean',linetype='Ecosystem'))\n",
    "plt = plt + geom_ribbon(aes(x='timestamp2', ymin='PARout_mean - PARout_sd', ymax='PARout_mean + PARout_sd', linetype='Ecosystem'), alpha=0.1)\n",
    "plt = plt + labs(x='Hour', y='$PAR_{out}\\; (\\mu mol \\; m^{-2} \\; s^{-1}$)', parse=True)\n",
    "plt = plt + facet_wrap(['Season'])\n",
    "#plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(size=9,rotation=30,hjust=0.5,weight='bold'),\n",
    "                  axis_title_x = element_blank(),\n",
    "                  axis_text_y=element_text(size=9,weight='bold'),\n",
    "                  strip_text=element_text(size=9,weight='bold'),\n",
    "                  legend_title=element_blank(),\n",
    "                  text=element_text(family=\"serif\"), axis_ticks_direction_y='in', axis_ticks_direction_x='in')\n",
    "plt = plt + theme(legend_position = 'top')\n",
    "plt = plt + scale_x_datetime(date_breaks = '6 hours', date_labels = '%H:%M')\n",
    "\n",
    "plt.save(graphs_path + 'PARout_diurnal.pdf', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "plt.save(graphs_path + 'PARout_diurnal.png', width=19, height=7, units='cm', scale=1.3, dpi=600)\n",
    "\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diurnal_Lout_desert_march2018_df = diurnal(all_df, 'Desert', 'March')\n",
    "diurnal_Lout_desert_march2018_df.to_csv(output_path + 'diurnal_Lout_desert_march2018.csv')\n",
    "\n",
    "diurnal_Lout_pv_march2018_df = diurnal(all_df, 'Solar', 'March')\n",
    "diurnal_Lout_pv_march2018_df.to_csv(output_path + 'diurnal_Lout_pv_march2018.csv')\n",
    "\n",
    "diurnal_Lout_desert_october2018_df = diurnal(all_df, 'Desert', 'October')\n",
    "diurnal_Lout_desert_october2018_df.to_csv(output_path + 'diurnal_Lout_desert_october2018.csv')\n",
    "\n",
    "diurnal_Lout_desert_july2019_df = diurnal(all_df, 'Desert', 'July')\n",
    "diurnal_Lout_desert_july2019_df.to_csv(output_path + 'diurnal_Lout_desert_july2019.csv') \n",
    "\n",
    "diurnal_Lout_pv_october2018_df = diurnal(all_df, 'Solar', 10)\n",
    "diurnal_Lout_pv_october2018_df.to_csv(output_path + 'diurnal_Lout_pv_october2018.csv')\n",
    "\n",
    "diurnal_Lout_pv_july2019_df = diurnal(all_df, 'Solar', 7)\n",
    "diurnal_Lout_pv_july2019_df.to_csv(output_path + 'diurnal_Lout_pv_july2019.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
