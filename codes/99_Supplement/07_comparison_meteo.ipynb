{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d317f1",
   "metadata": {},
   "source": [
    "# Comparison of meteo conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from plotnine import *\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format\n",
    "# Colours\n",
    "cbPalette = ['#939393', '#0072B2', '#E69F00', '#CC00CC', '#009E73', '#D55E00', '#CC79A7', '#FF3300', '#F0E442', '#56B4E9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53baa39-b207-4c53-b084-4a83327eb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './'\n",
    "\n",
    "data_path   = project_path + '../data/'\n",
    "# For the Ketura campaigns\n",
    "truck_ket_fn = data_path + 'Ketura_all_corr.csv'\n",
    "meteo_ket_fn  = data_path + 'Yotvata/'\n",
    "\n",
    "# For Yatir desert campaigns\n",
    "truck_yat_fn = data_path + 'Yatir desert/'\n",
    "meteo_yat_fn  = '../../data/towerSAS/Yatir_2000-2020.csv' # Here we use the Yatir tower data as a reference\n",
    "\n",
    "graphs_path = project_path + '../graphs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a64345",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070df4aa-741f-4563-b6cb-2a9421300691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tower(fn, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=None)\n",
    "    temp.rename({'date_mid_hour': 'DateTime'}, axis=1, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%d%b%y:%H:%M')\n",
    "    # Remove obsolete columns\n",
    "    temp.drop(['year','date','DOY','month','weekNo','mid_hour','mmyy','Bat_V','Hum_AC'], axis=1, inplace=True)\n",
    "    if (not silent): print(\"    \", '100.0 %\\t', fn.split('/')[-1])\n",
    "    return(temp)\n",
    "\n",
    "def load_truck(fn, index_col=False, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=index_col)\n",
    "    temp.rename(columns={'date_time': 'DateTime'}, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    temp['DateTime'] = temp['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(temp)\n",
    "\n",
    "def load_yatir_desert(directory, silent=False):\n",
    "    if (not silent):\n",
    "        print('  - Yatir desert:')\n",
    "        \n",
    "    file_list = sorted(glob.glob(directory + '**/*fixed.xls', recursive=True))\n",
    "    data_list = []\n",
    "    for idx, filename in enumerate(file_list):\n",
    "        print('    -', filename.split('/')[-1])\n",
    "        # Load gas data\n",
    "        temp1 = pd.read_excel(filename, sheet_name='derived (Data)', skiprows=2)\n",
    "        temp1['DateTime'] = pd.to_datetime(temp1['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        # Load radiation data\n",
    "        temp2 = pd.read_excel(filename, sheet_name='biomet (Data)', skiprows=2)\n",
    "        temp2['DateTime'] = pd.to_datetime(temp2['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        # Merge\n",
    "        temp = temp1.merge(temp2, on=['DateTime', 'time'], how='outer')\n",
    "        data_list.append(temp)\n",
    "    # Combine all the read data\n",
    "    df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    # Make the timestamp the middle of the halfhour\n",
    "    df['DateTime'] = df['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(df)\n",
    "\n",
    "def load_meteo_stn(directory, silent=False):\n",
    "    if (not silent):\n",
    "        print('  - Meteo station:')\n",
    "        \n",
    "    file_list = sorted(glob.glob(directory + '**/*.csv', recursive=True))\n",
    "    data_list = []\n",
    "    for idx, filename in enumerate(file_list):\n",
    "        print('    -', filename.split('/')[-1])\n",
    "        temp = pd.read_csv(filename)\n",
    "        data_list.append(temp)\n",
    "    # Combine all the read data\n",
    "    df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    # Fix problems\n",
    "    df.columns = ['station','DateTime', 'Eg_Wm2', 'RH_perc', 'Ta_C', 'u_ms']\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "    # Convert to numbers\n",
    "    df['Eg_Wm2'] = pd.to_numeric(df['Eg_Wm2'], errors='coerce')\n",
    "    df['RH_perc'] = pd.to_numeric(df['RH_perc'], errors='coerce')\n",
    "    df['Ta_C'] = pd.to_numeric(df['Ta_C'], errors='coerce')\n",
    "    df['u_ms'] = pd.to_numeric(df['u_ms'], errors='coerce')\n",
    "    # Average 10min Yotvata data to half-hours\n",
    "    df = df.resample('30min', on='DateTime').mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    df['DateTime'] = df['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(df)\n",
    "\n",
    "def pvalue_text(p):\n",
    "    if(p <= 0.001): p_text = '<.001'\n",
    "    if(p > 0.001): p_text = '<.01'\n",
    "    if(p > 0.01): p_text = '<.05'\n",
    "    if(p > 0.05): p_text = p.round(2).astype(str)\n",
    "    return(p_text)\n",
    "\n",
    "def add_season_info(DateTime, season_type='normal'):\n",
    "    # Create an empty Series of the same length as the available data\n",
    "    season = pd.Series(np.nan, index=range(len(DateTime)))\n",
    "    # Convert DateTime to numbers we can deal with\n",
    "    timestamp = DateTime.dt.strftime('%m%d').astype(int)\n",
    "    # Fill in the dates\n",
    "    if(season_type == 'high'):\n",
    "        season.loc[(timestamp >= 117)  & (timestamp <= 302)] = 'Winter'\n",
    "        season.loc[(timestamp >= 402)  & (timestamp <= 430)] = 'Spring'\n",
    "        season.loc[(timestamp >= 627)  & (timestamp <= 922)] = 'Summer'\n",
    "        season.loc[(timestamp >= 1008) & (timestamp <= 1128)] = 'Autumn'\n",
    "    else:\n",
    "        season.loc[(timestamp >= 1207) | (timestamp <= 330)] = 'Winter'\n",
    "        season.loc[(timestamp >= 331)  & (timestamp <= 530)] = 'Spring'\n",
    "        season.loc[(timestamp >= 531)  & (timestamp <= 922)] = 'Summer'\n",
    "        season.loc[(timestamp >= 923)  & (timestamp <= 1206)] = 'Autumn'\n",
    "    return(season)\n",
    "\n",
    "# Create annual daily values\n",
    "def make_daily_annual(temp, groups=[]):\n",
    "    temp = temp.copy()\n",
    "    temp['Day'] = temp['DateTime'].dt.strftime('%m-%d')\n",
    "    annual_df = temp.groupby(['Day'] + groups).mean()\n",
    "    annual_df.reset_index(inplace = True)\n",
    "    annual_df['DateTime'] = pd.to_datetime(annual_df['Day'], format='%m-%d')\n",
    "    return(annual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ea6f9-1880-41b6-8446-e2ae8980e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "# Load Ketura data\n",
    "truck_ket_df = load_truck(truck_ket_fn)\n",
    "meteo_ket_df = load_meteo_stn(meteo_ket_fn)\n",
    "\n",
    "# Load Yatir data\n",
    "truck_yat_df = load_yatir_desert(truck_yat_fn)\n",
    "\n",
    "yatir_full_df = load_tower(meteo_yat_fn) # Load 20 years\n",
    "#meteo_yat_df = yatir_full_df.loc[(yatir_full_df['DateTime'].dt.year >= 2018) & (yatir_full_df['DateTime'].dt.year <= 2019)].copy()\n",
    "meteo_yat_df = yatir_full_df.loc[(yatir_full_df['DateTime'].dt.year == 2013) | (yatir_full_df['DateTime'].dt.year == 2015)].copy()\n",
    "del [yatir_full_df] # Clean up memory\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52482d-45e0-4482-a82d-5721339bbb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meteo background in Yatir forest (our tower data)\n",
    "#--------------------------------------------------\n",
    "#display(meteo_yat_df.columns.values)\n",
    "# Rename columns from the tower dataframe\n",
    "meteo_yat_df.rename(columns={'S_top_atm(CM21_IV)_Wm-2': 'Sin'}, inplace=True)\n",
    "meteo_yat_df.rename(columns={'L_top_atm(PIR_IV)_Wm-2': 'Lin'}, inplace=True)\n",
    "meteo_yat_df.rename(columns={'RH 15m Vaisala_%': 'RH'}, inplace=True)\n",
    "meteo_yat_df.rename(columns={'Son_Hor_Wnd_Spd_m/s': 'u'}, inplace=True)\n",
    "meteo_yat_df.rename(columns={'Son_Wnd_Dir_Deg': 'u_dir'}, inplace=True)\n",
    "meteo_yat_df.rename(columns={'AirPress_Pa': 'Pa'}, inplace=True)\n",
    "# Calculate mean tower Ta\n",
    "meteo_yat_df['Ta'] = meteo_yat_df[['Prof_Tc_13m_C','Prof_Tc_15m_C','T 15m Vaisala_C','T_PIR_III_K']].mean(axis=1)\n",
    "# If any sensor is > 2째C from the mean, remove this sensor\n",
    "meteo_yat_df.loc[np.abs(meteo_yat_df['Ta'] - meteo_yat_df['Prof_Tc_13m_C']) > 2, 'Prof_Tc_13m_C'] = np.nan\n",
    "meteo_yat_df.loc[np.abs(meteo_yat_df['Ta'] - meteo_yat_df['Prof_Tc_15m_C']) > 2, 'Prof_Tc_15m_C'] = np.nan\n",
    "meteo_yat_df.loc[np.abs(meteo_yat_df['Ta'] - meteo_yat_df['T 15m Vaisala_C']) > 2, 'T 15m Vaisala_C'] = np.nan\n",
    "meteo_yat_df.loc[np.abs(meteo_yat_df['Ta'] - meteo_yat_df['T_PIR_III_K']) > 2, 'T_PIR_III_K'] = np.nan\n",
    "# Re-calculate the final mean tower Ta\n",
    "meteo_yat_df['Ta'] = meteo_yat_df[['Prof_Tc_13m_C','Prof_Tc_15m_C','T 15m Vaisala_C','T_PIR_III_K']].mean(axis=1)\n",
    "meteo_yat_df['Ecosystem'] = 'Change (Forest)'\n",
    "\n",
    "# Yatir desert data (truck)\n",
    "#--------------------------\n",
    "#display(truck_yat_df.columns.values)\n",
    "truck_yat_df.rename(columns={'SW_IN': 'Sin'}, inplace=True)\n",
    "truck_yat_df.rename(columns={'LW_IN': 'Lin'}, inplace=True)\n",
    "truck_yat_df.rename(columns={'TA': 'Ta'}, inplace=True)\n",
    "truck_yat_df.rename(columns={'PA_merge': 'Pa'}, inplace=True)\n",
    "#truck_yat_df.rename(columns={'RH_average': 'RH'}, inplace=True) # There is already an RH column\n",
    "truck_yat_df.rename(columns={'WS_average': 'u'}, inplace=True)\n",
    "truck_yat_df.rename(columns={'WD_average': 'u_dir'}, inplace=True)\n",
    "truck_yat_df['Ecosystem'] = 'Background (Desert)'\n",
    "\n",
    "# Convert from K to 째C\n",
    "truck_yat_df['Ta'] = truck_yat_df['Ta'] - 273.15\n",
    "\n",
    "# Remove bad days, only nighttime\n",
    "truck_yat_df = truck_yat_df.loc[~((truck_yat_df['DateTime'].dt.year == 2015) &\n",
    "                                (truck_yat_df['DateTime'].dt.month == 8) &\n",
    "                                (truck_yat_df['DateTime'].dt.day == 16))]\n",
    "truck_yat_df = truck_yat_df.loc[~((truck_yat_df['DateTime'].dt.year == 2015) &\n",
    "                                (truck_yat_df['DateTime'].dt.month == 8) &\n",
    "                                (truck_yat_df['DateTime'].dt.day == 30))]\n",
    "\n",
    "# Merge\n",
    "#------\n",
    "A = meteo_yat_df[['Ecosystem','DateTime','Sin','Lin','Ta','RH','u','u_dir','Pa']].copy().reset_index(drop=True)\n",
    "B = truck_yat_df[['Ecosystem','DateTime','Sin','Lin','Ta','RH','u','u_dir','Pa']].copy().reset_index(drop=True)\n",
    "A['Source'] = 'Meteo Station'\n",
    "B['Source'] = 'Mobile Lab'\n",
    "yat_df = pd.concat([A, B], axis=0, ignore_index=True)\n",
    "\n",
    "# Meteo background in Ketura (Yotvata)\n",
    "#-------------------------------------\n",
    "#display(meteo_ket_df.columns.values)\n",
    "meteo_ket_df.rename(columns={'Ta_C': 'Ta'}, inplace=True)\n",
    "meteo_ket_df.rename(columns={'RH_perc': 'RH'}, inplace=True)\n",
    "meteo_ket_df.rename(columns={'u_ms': 'u'}, inplace=True)\n",
    "meteo_ket_df.rename(columns={'Eg_Wm2': 'Sin'}, inplace=True)\n",
    "meteo_ket_df['Ecosystem'] = 'Meteo Station'\n",
    "\n",
    "# Ketura desert data (truck)\n",
    "#----------------------------\n",
    "#display(truck_ket_df.columns.values)\n",
    "truck_ket_df.rename(columns={'SW_IN_merge': 'Sin'}, inplace=True)\n",
    "truck_ket_df.rename(columns={'LW_IN_merge_corr': 'Lin'}, inplace=True)\n",
    "truck_ket_df.rename(columns={'Wind_speed': 'u'}, inplace=True)\n",
    "truck_ket_df.rename(columns={'Wind_direction': 'u_dir'}, inplace=True)\n",
    "truck_ket_df.rename(columns={'TA_merge': 'Ta'}, inplace=True)\n",
    "truck_ket_df.rename(columns={'RH': 'RH'}, inplace=True)\n",
    "\n",
    "# Convert from K to 째C\n",
    "truck_ket_df['Ta'] = truck_ket_df['Ta'] - 273.15\n",
    "\n",
    "# Merge\n",
    "#------\n",
    "A = meteo_ket_df[['Ecosystem','DateTime','Sin', 'Ta','RH','u']].copy().reset_index(drop=True)\n",
    "B = truck_ket_df[['Ecosystem','DateTime','Sin','Lin','Ta','RH','u','u_dir']].copy().reset_index(drop=True)\n",
    "A['Source'] = 'Meteo Station'\n",
    "B['Source'] = 'Mobile Lab'\n",
    "ket_df = pd.concat([A, B], axis=0, ignore_index=True)\n",
    "\n",
    "ket_df.loc[ket_df['Ecosystem'] == 'Solar', 'Ecosystem'] = 'Change (PV field)'\n",
    "ket_df.loc[ket_df['Ecosystem'] == 'Desert', 'Ecosystem'] = 'Background (Desert)'\n",
    "\n",
    "# Add season information\n",
    "#-----------------------\n",
    "# Yatir\n",
    "yat_df['season'] = add_season_info(yat_df['DateTime'])\n",
    "yat_df['high_season'] = add_season_info(yat_df['DateTime'], season_type = 'high')\n",
    "# Ketura\n",
    "ket_df['season'] = add_season_info(ket_df['DateTime'])\n",
    "ket_df['high_season'] = add_season_info(ket_df['DateTime'], season_type = 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1441792-acee-4634-8b50-096371d20e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make daily means\n",
    "ket_annual = make_daily_annual(ket_df, groups=['Ecosystem', 'Source'])\n",
    "ket_annual['Location'] = 'PV Field Area (Ketura)'\n",
    "\n",
    "yat_annual = make_daily_annual(yat_df, groups=['Ecosystem', 'Source'])\n",
    "yat_annual['Location'] = 'Forest Area (Yatir)'\n",
    "\n",
    "# Remove bad values\n",
    "ket_annual.loc[ket_annual['Sin'] > 400, 'Sin'] = np.nan # Remove half-day in Ketura PV field\n",
    "yat_annual.loc[yat_annual['Sin'] < 10, 'Sin'] = np.nan # Remove outlier in Yatir forest data\n",
    "\n",
    "# Append two dataframes\n",
    "annual_df = pd.concat([yat_annual, ket_annual], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b51e8-607c-466e-ac30-5944eb6deee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare\n",
    "#--------\n",
    "# Convert to long format\n",
    "annual_long = pd.melt(annual_df[['DateTime', 'Source', 'Location', 'Sin', 'Ta', 'RH', 'u']], id_vars=['DateTime', 'Source', 'Location'])\n",
    "# Adjust labels\n",
    "annual_long.loc[annual_long['variable'] == 'Sin', 'variable'] = '$S_{in}$ [$W~m^{-2}$]'\n",
    "annual_long.loc[annual_long['variable'] == 'Ta', 'variable'] = '$T_{a}$ [째C]'\n",
    "annual_long.loc[annual_long['variable'] == 'RH', 'variable'] = '$RH$ [%]'\n",
    "annual_long.loc[annual_long['variable'] == 'u', 'variable'] = '$u$ [$m~s^{-1}$]'\n",
    "\n",
    "# Make figure\n",
    "#--------------\n",
    "plt = ggplot(annual_long)\n",
    "plt = plt + geom_point(aes(x='DateTime', y='value', colour = 'Source'), size=0.5)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + theme(axis_text_x=element_text(angle=45),\n",
    "                  axis_title_x=element_blank(), axis_title_y=element_blank())\n",
    "plt = plt + labs(x='Month', y='$S_{in}$ [$W~m^{-2}$]', colour = 'Source')\n",
    "plt = plt + scale_x_datetime(breaks=date_breaks('1 month'), labels=date_format('%b'))\n",
    "plt = plt + scale_colour_manual(values=cbPalette) + scale_fill_manual(values=cbPalette)\n",
    "plt = plt + facet_grid('variable ~ Location', scales='free_y')\n",
    "print(plt)\n",
    "\n",
    "plt.save(graphs_path + 'meteo_parameters.png', width=1.6*15, height=1.6*7.5, units='cm', dpi=600)\n",
    "plt.save(graphs_path + 'meteo_parameters.pdf', width=1.6*15, height=1.6*7.5, units='cm', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6ee4b-f316-4427-9f83-c9b2a052c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b97369-f054-43d7-be45-72c5e08fb03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f150311-dfcb-4099-af0e-db5cfbaf6404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
