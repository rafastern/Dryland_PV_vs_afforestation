{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975b784b-a542-46ff-ac6b-77ceae89eb23",
   "metadata": {},
   "source": [
    "# PV field albedo from percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7471b1d4-c424-47d4-98e3-976d54682d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from plotnine import *\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31507be4-2c7f-4979-9d2a-3eda114002c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "project_path = './'\n",
    "data_path = project_path + '../data/'\n",
    "\n",
    "# Input path\n",
    "percentage_fn = data_path + 'temperature_by_element.csv'\n",
    "ketura_fn     = data_path + 'Ketura_all_corr.csv'\n",
    "yatir_fn      = project_path + '../../data/towerSAS/Yatir_2000-2020.csv'\n",
    "\n",
    "# Output path\n",
    "graphs_path = project_path + '../graphs/'\n",
    "\n",
    "# Constants\n",
    "albedo_pv   = 0.05\n",
    "panel_angle = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b3334-ca55-4789-ac82-9ad97c58d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tower(fn, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=None)\n",
    "    temp.rename({'date_mid_hour': 'DateTime'}, axis=1, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%d%b%y:%H:%M')\n",
    "    # Remove obsolete columns\n",
    "    temp.drop(['year','date','DOY','month','weekNo','mid_hour','mmyy','Bat_V','Hum_AC'], axis=1, inplace=True)\n",
    "    if (not silent): print(\"    \", '100.0 %\\t', fn.split('/')[-1])\n",
    "    return(temp)\n",
    "\n",
    "def load_truck(fn, index_col=False, silent=False):\n",
    "    if (not silent):\n",
    "        print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn, index_col=index_col)\n",
    "    temp.rename(columns={'date_time': 'DateTime'}, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    temp['DateTime'] = temp['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    return(temp)\n",
    "\n",
    "def load_percentage(fn, silent=False):\n",
    "    if (not silent): print('  -', fn.split('/')[-1])\n",
    "    temp = pd.read_csv(fn)\n",
    "    \n",
    "    temp.rename(columns={'date_time': 'DateTime'}, inplace=True)\n",
    "    temp['DateTime'] = pd.to_datetime(temp['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    #temp['DateTime'] = temp['DateTime'] + pd.Timedelta(minutes=15)\n",
    "    # Move timestamp to front\n",
    "    col = temp.pop('DateTime')\n",
    "    temp.insert(0, col.name, col, allow_duplicates=True)\n",
    "    \n",
    "    # Remove obsolete columns\n",
    "    temp.drop(['Unnamed: 0','flight'], axis=1, inplace=True)\n",
    "    # Change to wide format\n",
    "    wide = pd.pivot(temp, index='DateTime', columns='label', values='coverage_percent')\n",
    "    wide.reset_index(inplace=True)\n",
    "    \n",
    "    # Normalise the % to 100%, because sometimes it only reaches 96% total\n",
    "    wide.loc[wide['sun'].isna(), 'sun'] = 0\n",
    "    wide['total'] = wide['panel'] + wide['shadow'] + wide['soil'] + wide['sun']\n",
    "    wide['sun']    = wide['sun'] * 100 / wide['total']\n",
    "    wide['panel']  = wide['panel'] * 100 / wide['total']\n",
    "    wide['shadow'] = wide['shadow'] * 100 / wide['total']\n",
    "    wide['soil']   = wide['soil'] * 100 / wide['total']\n",
    "    wide.drop(['total'], axis=1, inplace=True)\n",
    "    \n",
    "    return(wide)\n",
    "\n",
    "def add_ecosystem(df):\n",
    "    df = df.copy()\n",
    "    # Add ecosystem\n",
    "    df['Ecosystem'] = np.nan\n",
    "    df.loc[(df['DateTime'] >= '2018-10-16') & (df['DateTime'] < '2018-10-24'), 'Ecosystem'] = 'Desert background'\n",
    "    df.loc[(df['DateTime'] >= '2018-10-24') & (df['DateTime'] < '2018-11-01'), 'Ecosystem'] = 'PV field'\n",
    "    \n",
    "    df.loc[(df['DateTime'] >= '2019-07-09') & (df['DateTime'] < '2019-07-16'), 'Ecosystem'] = 'Desert background'\n",
    "    df.loc[(df['DateTime'] >= '2019-07-16') & (df['DateTime'] < '2019-07-24'), 'Ecosystem'] = 'PV field'\n",
    "    # Season\n",
    "    df['Season'] = np.nan\n",
    "    df.loc[df['DateTime'].dt.year == 2018, 'Season'] = 'Autumn'\n",
    "    df.loc[df['DateTime'].dt.year == 2019, 'Season'] = 'Summer'\n",
    "    # Create day identifier\n",
    "    df['time'] = df['DateTime'].dt.strftime('%H:%M')\n",
    "    # shift column 'timestamp' to first position\n",
    "    col = df.pop('time')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('Ecosystem')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('Season')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    col = df.pop('DateTime')\n",
    "    df.insert(0, col.name, col, allow_duplicates=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5d4880-472b-4394-8001-b85e20b79191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "  - Ketura_all_corr.csv\n",
      "  - temperature_by_element.csv\n",
      "  - Yatir_2000-2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\.conda\\envs\\dp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     100.0 %\t Yatir_2000-2020.csv\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "ketura_df = load_truck(ketura_fn)\n",
    "ketura_df = add_ecosystem(ketura_df)\n",
    "\n",
    "perc_df = load_percentage(percentage_fn)\n",
    "perc_df = add_ecosystem(perc_df)\n",
    "\n",
    "# Required for diffuse fraction (taking into account shade albedo)\n",
    "yatir_full_df = load_tower(yatir_fn) # Load 20 years\n",
    "yatir_df = yatir_full_df.loc[(yatir_full_df['DateTime'].dt.year == 2018) | (yatir_full_df['DateTime'].dt.year == 2019)].copy()\n",
    "del [yatir_full_df] # Clean up memory\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43758b-4742-49cf-993d-6b21763ed210",
   "metadata": {},
   "source": [
    "## Trigonometric calculations with position of the sun (no shade albedo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a40946-0972-4e31-bf08-48f7dabd4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that shade does not participated in the surface energy budget (or is negligibly small):\n",
    "# Normalise area based on \"no shade\" scenario:\n",
    "\n",
    "# \"Flatten\" the pv panels\n",
    "perc_df['panel_flat'] = perc_df['panel'] / np.cos(np.radians(panel_angle))\n",
    "\n",
    "# Normalise the % to 100%, because sometimes it only reaches 96% total\n",
    "perc_df['total'] = perc_df['panel_flat'] + perc_df['soil']\n",
    "perc_df['panel_norm']  = perc_df['panel_flat'] * 100 / perc_df['total']\n",
    "perc_df['soil_norm']   = perc_df['soil'] * 100 / perc_df['total']\n",
    "perc_df.drop(['total'], axis=1, inplace=True)\n",
    "\n",
    "#display(perc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64583afd-14dc-41e6-bc37-a91e2b866212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse percentages to diurnals\n",
    "perc_df['DateTime'] = pd.to_datetime(perc_df['time'], format='%H:%M')\n",
    "\n",
    "# set the DateTime column as the index\n",
    "perc_df.set_index('DateTime', inplace=True)\n",
    "# resample the data to 15-minute intervals and apply a smoothing function (e.g., rolling mean)\n",
    "df_resampled = perc_df.groupby(['Ecosystem', 'Season']).resample('15T').mean().rolling(window=6, min_periods=3).mean()\n",
    "df_resampled.reset_index(inplace=True)\n",
    "\n",
    "df_resampled['time'] = df_resampled['DateTime'].dt.strftime('%H:%M')\n",
    "col = df_resampled.pop('time')\n",
    "df_resampled.insert(0, col.name, col, allow_duplicates=True)\n",
    "df_resampled.drop(['DateTime'], axis=1, inplace=True)\n",
    "\n",
    "perc_df.reset_index(inplace=True)\n",
    "#display(df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2c5d14-0429-4dc3-8308-1c2b38d9a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add percentages\n",
    "ketura = ketura_df.merge(df_resampled, how='left',  on=['Ecosystem','Season','time'])\n",
    "\n",
    "# Fix bad SW values\n",
    "ketura.loc[ketura['SW_IN_merge'] < 0, 'SW_IN_merge'] = 0\n",
    "ketura.loc[ketura['SW_OUT_merge'] < 0, 'SW_OUT_merge'] = 0\n",
    "ketura.loc[ketura['SW_IN_merge'] <= 0, 'SW_OUT_merge'] = 0\n",
    "\n",
    "# Re-calculate albedo from SW measurements (relevant for the desert)\n",
    "ketura['albedo'] = np.nan\n",
    "ketura['albedo'] = ketura['SW_OUT_merge'] / ketura['SW_IN_merge']\n",
    "\n",
    "# Extract desert albedo & rename. This will be used for the soil & shade fractions of the PV field\n",
    "desert_albedo = ketura.loc[ketura['Ecosystem'] == 'Desert background',['time','Season','albedo']].copy()\n",
    "desert_albedo.rename({'albedo': 'albedo_soil'}, axis=1, inplace=True)\n",
    "\n",
    "# Merge desert soil albedo\n",
    "ketura = ketura.merge(desert_albedo, how='left',  on=['Season','time'])\n",
    "\n",
    "# Calculate PV field albedo, use the different albedos\n",
    "ketura.loc[ketura['Ecosystem'] == 'PV field', 'albedo_no_shade'] = ketura.loc[ketura['Ecosystem'] == 'PV field', 'albedo_soil'] \\\n",
    "                                                        * ketura.loc[ketura['Ecosystem'] == 'PV field', 'soil_norm'] \\\n",
    "                                                        + albedo_pv \\\n",
    "                                                        * ketura.loc[ketura['Ecosystem'] == 'PV field', 'panel_norm']\n",
    "\n",
    "# Convert albedo to fraction, not %\n",
    "ketura['albedo_no_shade'] = ketura['albedo_no_shade']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a6ba30-ab45-4efb-8efd-2e8af692e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summer:\n",
      "(0.19454282111273694, 0.0028230961282562743, 0.20127448471107937, 0.19004013604377584)\n",
      "\n",
      "Autumn:\n",
      "(0.14443579616868824, 0.016691545783676265, 0.1938996151174148, 0.11574344646458533)\n"
     ]
    }
   ],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    values = np.ma.masked_invalid(values)\n",
    "    # Return the weighted average and standard deviation.\n",
    "    average = np.ma.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.ma.average((values-average)**2, weights=weights)\n",
    "    \n",
    "    maximum = np.max(values)\n",
    "    minimum = np.min(values)\n",
    "    return (average, np.sqrt(variance), maximum, minimum)\n",
    "\n",
    "print('Summer:')\n",
    "summer = ketura.loc[(ketura['Ecosystem'] == 'PV field') & (ketura['Season'] == 'Summer')]\n",
    "print(weighted_avg_and_std(summer['albedo_no_shade'], summer['SW_IN_merge']))\n",
    "print()\n",
    "\n",
    "print('Autumn:')\n",
    "autumn = ketura.loc[(ketura['Ecosystem'] == 'PV field') & (ketura['Season'] == 'Autumn')]\n",
    "print(weighted_avg_and_std(autumn['albedo_no_shade'], autumn['SW_IN_merge']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8279a58-edb9-4fb0-84b1-a6fe95b67963",
   "metadata": {},
   "source": [
    "## No trigonometric calculation (taking into account shade albedo as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258306f4-3f0d-4517-b331-5a4c89224188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse percentages to diurnals\n",
    "perc_df['DateTime'] = pd.to_datetime(perc_df['time'], format='%H:%M')\n",
    "\n",
    "# set the DateTime column as the index\n",
    "perc_df.set_index('DateTime', inplace=True)\n",
    "# resample the data to 15-minute intervals and apply a smoothing function (e.g., rolling mean)\n",
    "df_resampled = perc_df.groupby(['Ecosystem', 'Season']).resample('15T').mean().rolling(window=6, min_periods=3).mean()\n",
    "df_resampled.reset_index(inplace=True)\n",
    "\n",
    "df_resampled['time'] = df_resampled['DateTime'].dt.strftime('%H:%M')\n",
    "col = df_resampled.pop('time')\n",
    "df_resampled.insert(0, col.name, col, allow_duplicates=True)\n",
    "df_resampled.drop(['DateTime'], axis=1, inplace=True)\n",
    "\n",
    "perc_df.reset_index(inplace=True)\n",
    "#display(df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab070e6f-61cf-4b5b-aa2b-efc42425baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate diffuse fraction in Yatir (Assuming it's the same in Ketura)\n",
    "yatir_df['f_dif'] = yatir_df['S_top_diff(CM21_V)_Wm-2'] / yatir_df['S_top_atm(CM21_IV)_Wm-2']\n",
    "\n",
    "# Add diffuse fraction from Yatir to Ketura\n",
    "ketura = ketura_df.merge(yatir_df[['DateTime','f_dif']], how='left', on=['DateTime'])\n",
    "\n",
    "# Add percentages\n",
    "ketura = ketura.merge(df_resampled, how='left',  on=['Ecosystem','Season','time'])\n",
    "\n",
    "# Fix bad SW values\n",
    "ketura.loc[ketura['SW_IN_merge'] < 0, 'SW_IN_merge'] = 0\n",
    "ketura.loc[ketura['SW_OUT_merge'] < 0, 'SW_OUT_merge'] = 0\n",
    "ketura.loc[ketura['SW_IN_merge'] <= 0, 'SW_OUT_merge'] = 0\n",
    "\n",
    "# Re-calculate albedo from SW measurements (relevant for the desert)\n",
    "ketura['albedo'] = np.nan\n",
    "ketura['albedo'] = ketura['SW_OUT_merge'] / ketura['SW_IN_merge']\n",
    "\n",
    "# Extract desert albedo & rename. This will be used for the soil & shade fractions of the PV field\n",
    "desert_albedo = ketura.loc[ketura['Ecosystem'] == 'Desert background',['time','Season','albedo']].copy()\n",
    "desert_albedo.rename({'albedo': 'albedo_soil'}, axis=1, inplace=True)\n",
    "#display(desert_albedo.loc[desert_albe])\n",
    "\n",
    "# Merge desert soil albedo\n",
    "ketura = ketura.merge(desert_albedo, how='left',  on=['Season','time'])\n",
    "\n",
    "# Calculate shade albedo\n",
    "ketura['albedo_shade'] = ketura['albedo_soil'] * ketura['f_dif']\n",
    "\n",
    "# Calculate PV field albedo, use the different albedos\n",
    "ketura.loc[ketura['Ecosystem'] == 'PV field', 'albedo_with_shade'] = ketura.loc[ketura['Ecosystem'] == 'PV field', 'albedo_soil'] \\\n",
    "                                                        * ketura.loc[ketura['Ecosystem'] == 'PV field', 'soil'] \\\n",
    "                                                        + ketura.loc[ketura['Ecosystem'] == 'PV field', 'albedo_shade'] \\\n",
    "                                                        * ketura.loc[ketura['Ecosystem'] == 'PV field', 'shadow'] \\\n",
    "                                                        + albedo_pv \\\n",
    "                                                        * ketura.loc[ketura['Ecosystem'] == 'PV field', 'panel']\n",
    "\n",
    "# Convert albedo to fraction, not %\n",
    "ketura['albedo_with_shade'] = ketura['albedo_with_shade']/100\n",
    "\n",
    "#display(ketura.loc[~ketura['f_dif'].isna()])\n",
    "\n",
    "#print(ketura.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e24bd2-a969-4933-8710-caf13c8b06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summer:\n",
      "(0.19880982835997008, 0.003966225302099919, 0.20793598124994594, 0.19278360029596173)\n",
      "\n",
      "Autumn:\n",
      "(0.14105746107276582, 0.027984517948550423, 0.23761007637864348, 0.0950338235120522)\n"
     ]
    }
   ],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    values = np.ma.masked_invalid(values)\n",
    "    # Return the weighted average and standard deviation.\n",
    "    average = np.ma.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.ma.average((values-average)**2, weights=weights)\n",
    "    \n",
    "    maximum = np.max(values)\n",
    "    minimum = np.min(values)\n",
    "    return (average, np.sqrt(variance), maximum, minimum)\n",
    "\n",
    "print('Summer:')\n",
    "summer = ketura.loc[(ketura['Ecosystem'] == 'PV field') & (ketura['Season'] == 'Summer')]\n",
    "print(weighted_avg_and_std(summer['albedo_with_shade'], summer['SW_IN_merge']))\n",
    "print()\n",
    "\n",
    "print('Autumn:')\n",
    "autumn = ketura.loc[(ketura['Ecosystem'] == 'PV field') & (ketura['Season'] == 'Autumn')]\n",
    "print(weighted_avg_and_std(autumn['albedo_with_shade'], autumn['SW_IN_merge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d67982-f1f1-4720-b003-5414e1a390cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
